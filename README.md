# ML Project for ESG Score Prediction


> **âš ï¸ FOR CLAUDE/AI ASSISTANTS: Please read README-CLAUDE.md before making any changes**

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Usage Guide](#usage-guide)
- [Project Structure](#project-structure)
- [Models](#models)
- [Output Structure](#output-structure)
- [Troubleshooting](#troubleshooting)
- [Development](#development)
- [Contributing](#contributing)

## ğŸ¯ Overview

This project implements a comprehensive machine learning pipeline for ESG (Environmental, Social, and Governance) score prediction. It features multiple ML models, robust evaluation metrics, and extensive visualization capabilities.

### Key Features
- **Multiple ML Models**: Linear Regression, ElasticNet, XGBoost, LightGBM, and CatBoost
- **Native Categorical Support**: Efficient handling of categorical features for tree-based models
- **Comprehensive Evaluation**: Cross-validation, baseline comparisons, feature importance analysis
- **Rich Visualizations**: SHAP values, residual plots, feature importance, model comparisons
- **Optuna Integration**: Hyperparameter optimization for all models
- **Modular Architecture**: Clean separation of concerns with adapters for different model types

## ğŸš€ Quick Start

### Installation

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd ml_project_refactored
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Prepare data directories**:
   ```bash
   mkdir -p data/{raw,processed,interim}
   mkdir -p outputs/{models,visualizations,metrics,reports}
   mkdir -p logs
   ```

### Basic Usage

```bash
# Run complete pipeline
python main.py --all

# Train only tree models
python main.py --train

# Train linear models
python main.py --train-linear

# Evaluate all models
python main.py --evaluate

# Generate visualizations
python main.py --visualize
```

## ğŸ“˜ Usage Guide

### Training Models

#### Train All Models
```bash
python main.py --train --train-linear
```

#### Train Specific Model Types
```bash
# XGBoost models
python main.py --train-xgboost

# LightGBM models
python main.py --train-lightgbm

# CatBoost models
python main.py --train-catboost

# ElasticNet with optimization
python main.py --train-linear-elasticnet --optimize-elasticnet 100
```

### Hyperparameter Optimization

```bash
# Optimize XGBoost with 50 trials
python main.py --optimize-xgboost 50

# Optimize LightGBM with 50 trials
python main.py --optimize-lightgbm 50

# Optimize CatBoost with 50 trials
python main.py --optimize-catboost 50

# Force retuning even if studies exist
python main.py --optimize-xgboost 50 --force-retune
```

### Model Evaluation

```bash
# Evaluate all models
python main.py --evaluate

# Generate feature importance analysis
python main.py --importance

# Analyze multicollinearity
python main.py --vif
```

### Visualization Generation

```bash
# Generate all visualizations
python main.py --visualize

# Generate model-specific visualizations
python main.py --visualize-xgboost
python main.py --visualize-lightgbm
python main.py --visualize-catboost
```

### Dataset Selection

```bash
# Train on specific datasets
python main.py --train --datasets LR_Base LR_Yeo

# Train on all datasets (default)
python main.py --train --datasets all
```

## ğŸ“ Project Structure

```
ml_project_refactored/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/           # Configuration settings
â”‚   â”œâ”€â”€ data/            # Data loading and preprocessing
â”‚   â”œâ”€â”€ models/          # Model implementations
â”‚   â”œâ”€â”€ evaluation/      # Evaluation metrics and analysis
â”‚   â”œâ”€â”€ pipelines/       # Pipeline orchestration
â”‚   â”œâ”€â”€ utils/           # Utility functions
â”‚   â””â”€â”€ visualization/   # Visualization system
â”‚       â”œâ”€â”€ adapters/    # Model adapters
â”‚       â”œâ”€â”€ core/        # Core visualization infrastructure
â”‚       â”œâ”€â”€ plots/       # Plot implementations
â”‚       â””â”€â”€ components/  # Reusable components
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Original data files
â”‚   â”œâ”€â”€ processed/      # Processed datasets
â”‚   â””â”€â”€ pkl/            # Pickled objects
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/         # Trained models
â”‚   â”œâ”€â”€ visualizations/ # Generated plots
â”‚   â”œâ”€â”€ metrics/        # Evaluation results
â”‚   â””â”€â”€ reports/        # Analysis reports
â”œâ”€â”€ scripts/            # Utility scripts
â”œâ”€â”€ tests/              # Unit tests
â””â”€â”€ docs/               # Documentation
```

## ğŸ¤– Models

### Linear Models
- **Linear Regression**: Basic and Random feature variants
- **ElasticNet**: With Optuna hyperparameter optimization

### Tree-Based Models
- **XGBoost**: Gradient boosting with native categorical support
- **LightGBM**: Fast gradient boosting with categorical features
- **CatBoost**: Gradient boosting optimized for categorical data

### Model Variants
Each model is trained on four dataset variants:
1. **Base**: Original features
2. **Yeo**: Yeo-Johnson transformed features
3. **Base_Random**: Base + random feature
4. **Yeo_Random**: Yeo + random feature

## ğŸ“Š Output Structure

### Trained Models
```
outputs/models/
â”œâ”€â”€ <ModelType>_<Dataset>_<Config>.pkl
â””â”€â”€ optuna_studies/
    â””â”€â”€ <ModelType>_<Dataset>_study.pkl
```

### Visualizations
```
outputs/visualizations/
â”œâ”€â”€ features/           # Feature importance plots
â”œâ”€â”€ performance/        # Model performance plots
â”œâ”€â”€ residuals/         # Residual analysis
â”œâ”€â”€ shap/              # SHAP value visualizations
â”œâ”€â”€ comparisons/       # Model comparisons
â””â”€â”€ optimization/      # Optuna optimization plots
```

### Metrics
```
outputs/metrics/
â”œâ”€â”€ model_metrics.csv          # All model metrics
â”œâ”€â”€ baseline_comparison.csv    # Baseline comparisons
â”œâ”€â”€ vif_analysis.csv          # VIF results
â””â”€â”€ feature_importance/       # Feature importance by model
```

## ğŸ”§ Troubleshooting

### Common Issues

1. **Pipeline Hanging**
   - Use `python run_pipeline_safe.py` for better error handling
   - Check logs in `logs/` directory

2. **Memory Issues with SHAP**
   - Use memory-safe generation scripts in `scripts/utilities/`
   - Reduce sample size for SHAP calculations

3. **Missing CV Scores**
   - Some models may not have CV scores for Booster objects
   - Check model pickle files for available metrics

4. **Import Errors**
   - Ensure virtual environment is activated
   - Check `requirements.txt` for missing dependencies

### Debug Mode

Enable detailed logging:
```bash
python main.py --all 2>&1 | tee debug.log
```

## ğŸ› ï¸ Development

### Code Style
- Follow PEP 8 guidelines
- Use NumPy-style docstrings
- Format with `black`
- Lint with `flake8`

### Testing
```bash
# Run all tests
python -m pytest tests/

# Run specific test file
python -m pytest tests/test_models.py

# Run with coverage
python -m pytest --cov=src tests/
```

### Adding New Models

1. Create model class in `src/models/`
2. Create adapter in `src/visualization/adapters/`
3. Register in visualization factory
4. Update pipeline configuration

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

### Contribution Guidelines
- Write tests for new features
- Update documentation
- Follow existing code style
- Add docstrings to new functions

## ğŸ“ License

[Add license information here]

## ğŸ™ Acknowledgments

- Built with scikit-learn, XGBoost, LightGBM, CatBoost
- Visualization powered by matplotlib, seaborn, and SHAP
- Hyperparameter optimization by Optuna

---

For detailed technical documentation, see the `docs/` directory.