{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "This notebook implement linear regression on the data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Load Libraries and Data\n",
    "\n",
    "Import the necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression for ESG Score Prediction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n",
    "# Define a dictionary to store model metrics\n",
    "model_metrics = {}\n",
    "\n",
    "# Create an output directory for our results\n",
    "os.makedirs('strat_linreg_eval_metrics', exist_ok=True)\n",
    "\n",
    "# After running all your models and having model_metrics dictionary populated\n",
    "from thesis_visualizations import visualize_complete_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1. Set up data paths\n",
    "class Location:\n",
    "    \"\"\"\n",
    "    Helper class for managing file paths.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dir):\n",
    "        \"\"\"\n",
    "        Initialize with the base directory.\n",
    "        \"\"\"\n",
    "        self.base_dir = base_dir\n",
    "        \n",
    "    def get_path(self, subdirectory, filename):\n",
    "        \"\"\"\n",
    "        Get full path for a file in a subdirectory.\n",
    "        \"\"\"\n",
    "        return os.path.join(self.base_dir, subdirectory, filename)\n",
    "\n",
    "base_dir = os.getcwd()    \n",
    "location = Location(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Columns (sample): ['market_cap_usd', 'net_income_usd', 'hist_pe', 'hist_book_px', 'hist_fcf_yld']\n",
      "Yeo Columns (sample): ['yeo_joh_market_cap_usd', 'yeo_joh_net_income_usd', 'yeo_joh_hist_pe', 'yeo_joh_hist_book_px', 'yeo_joh_hist_fcf_yld']\n"
     ]
    }
   ],
   "source": [
    "# 1.2. Load column lists\n",
    "subdirectory='pkl'\n",
    "with open(location.get_path(subdirectory, 'base_columns.pkl'), 'rb') as f:\n",
    "    base_columns = pickle.load(f)\n",
    "\n",
    "with open(location.get_path(subdirectory, 'yeo_columns.pkl'), 'rb') as f:\n",
    "    yeo_columns = pickle.load(f)\n",
    "\n",
    "print(\"Base Columns (sample):\", base_columns[:5])\n",
    "print(\"Yeo Columns (sample):\", yeo_columns[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3. Load feature and target data\n",
    "subdirectory = 'data'\n",
    "feature_path = location.get_path(subdirectory, 'combined_df_for_ml_models.csv')\n",
    "feature_df = pd.read_csv(feature_path, index_col='issuer_name')\n",
    "feature_df = feature_df.convert_dtypes()\n",
    "feature_df.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "score_path = location.get_path(subdirectory, 'score.csv')\n",
    "score_df = pd.read_csv(score_path, index_col='issuer_name')\n",
    "score_df = score_df.convert_dtypes()\n",
    "score_df.sort_index(ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature data shape: (2202, 388)\n",
      "Score data shape: (2202, 1)\n",
      "\n",
      "Score data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esg_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issuer_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10X Genomics Inc</th>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3I GROUP PLC</th>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3M COMPANY</th>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A. O. SMITH CORPORATION</th>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.P. MOELLER - MAERSK A/S</th>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           esg_score\n",
       "issuer_name                         \n",
       "10X Genomics Inc                 4.6\n",
       "3I GROUP PLC                     9.7\n",
       "3M COMPANY                       9.5\n",
       "A. O. SMITH CORPORATION          4.8\n",
       "A.P. MOELLER - MAERSK A/S        7.6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Feature data shape:\", feature_df.shape)\n",
    "print(\"Score data shape:\", score_df.shape)\n",
    "print(\"\\nScore data preview:\")\n",
    "score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base feature data shape: (2202, 362)\n",
      "Yeo data shape: (2202, 362)\n"
     ]
    }
   ],
   "source": [
    "# 1.4. Create feature sets and target variable\n",
    "LR_Base = feature_df[base_columns]\n",
    "LR_Yeo = feature_df[yeo_columns]\n",
    "y = score_df\n",
    "print(\"Base feature data shape:\", LR_Base.shape)\n",
    "print(\"Yeo data shape:\", LR_Yeo.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new datasets with random features\n",
      "X_base_random shape: (2202, 363)\n",
      "X_yeo_random shape: (2202, 363)\n"
     ]
    }
   ],
   "source": [
    "# Create copies with random variables added\n",
    "LR_Base_random = LR_Base.copy()\n",
    "LR_Yeo_random = LR_Yeo.copy()\n",
    "\n",
    "# Add random variables to the copies\n",
    "np.random.seed(42)  # For reproducibility\n",
    "LR_Base_random['random_feature'] = np.random.normal(0, 1, size=LR_Base.shape[0])\n",
    "LR_Yeo_random['random_feature'] = np.random.normal(0, 1, size=LR_Yeo.shape[0])\n",
    "\n",
    "print(\"Created new datasets with random features\")\n",
    "print(f\"X_base_random shape: {LR_Base_random.shape}\")\n",
    "print(f\"X_yeo_random shape: {LR_Yeo_random.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Stratified shuffle function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def perform_stratified_split_by_sector(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs a stratified train-test split based on GICS sectors.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pandas.DataFrame\n",
    "        Feature dataframe\n",
    "    y : pandas.DataFrame or Series\n",
    "        Target variable (ESG scores)\n",
    "    test_size : float, default=0.2\n",
    "        Proportion of the dataset to include in the test split\n",
    "    random_state : int, default=42\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X_train, X_test, y_train, y_test : Dataframes split while preserving sector proportions\n",
    "    \"\"\"\n",
    "    # Extract sector columns - these start with 'gics_sector_'\n",
    "    sector_columns = [col for col in X.columns if col.startswith('gics_sector_')]\n",
    "    \n",
    "    # Create a sector label for each company (convert one-hot to single label)\n",
    "    # We need a single column for stratification\n",
    "    sector_data = X[sector_columns].copy()\n",
    "    sector_labels = np.zeros(len(X), dtype=int)\n",
    "    \n",
    "    for i, col in enumerate(sector_columns):\n",
    "        # Assign a unique integer to each sector\n",
    "        sector_labels[sector_data[col] == 1] = i\n",
    "    \n",
    "    # Initialize stratified split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Get train and test indices preserving sector proportions\n",
    "    for train_idx, test_idx in sss.split(X, sector_labels):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Verify sector distributions are maintained\n",
    "    print(\"Sector distribution check:\")\n",
    "    for i, col in enumerate(sector_columns):\n",
    "        train_pct = X_train[col].mean() * 100\n",
    "        test_pct = X_test[col].mean() * 100\n",
    "        print(f\"{col.replace('gics_sector_', '')}: Train {train_pct:.1f}%, Test {test_pct:.1f}%\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Linear model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume model_metrics is a global dict for storing summary results\n",
    "\n",
    "def run_regression_model(X_data, y_data, model_name, \n",
    "                         model_type=\"linear\", \n",
    "                         alpha=None, l1_ratio=None,\n",
    "                         random_state=42, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Run regression on the provided data and evaluate performance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_data : pandas.DataFrame\n",
    "        Feature data\n",
    "    y_data : pandas.Series or DataFrame\n",
    "        Target variable\n",
    "    model_name : str\n",
    "        Identifier for the model\n",
    "    model_type : str, default=\"linear\"\n",
    "        Type of model: \"linear\" or \"elasticnet\"\n",
    "    alpha : float, optional\n",
    "        Regularization strength (used if model_type == \"elasticnet\")\n",
    "    l1_ratio : float, optional\n",
    "        L1/L2 mixing ratio (used if model_type == \"elasticnet\")\n",
    "    random_state : int, default=42\n",
    "        Reproducibility seed\n",
    "    test_size : float, default=0.2\n",
    "        Proportion of data for testing\n",
    "    \"\"\"\n",
    "    global model_metrics  # Use the global metrics dictionary\n",
    "    \n",
    "    # Use stratified split by sector\n",
    "    X_train, X_test, y_train, y_test = perform_stratified_split_by_sector(\n",
    "        X_data, y_data, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Select and initialize model\n",
    "    if model_type == \"linear\":\n",
    "        model = LinearRegression()\n",
    "    elif model_type == \"elasticnet\":\n",
    "        if alpha is None or l1_ratio is None:\n",
    "            raise ValueError(\"ElasticNet requires both alpha and l1_ratio.\")\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=random_state)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model_type: {model_type}\")\n",
    "\n",
    "    # Fit and predict\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Logging\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE : {mae:.4f}\")\n",
    "    print(f\"  MSE : {mse:.4f}\")\n",
    "    print(f\"  R²  : {r2:.4f}\")\n",
    "\n",
    "    model_metrics[model_name] = {\n",
    "    'RMSE': rmse,\n",
    "    'MAE': mae,\n",
    "    'MSE': mse,\n",
    "    'R2': r2,\n",
    "    'n_companies': len(X_data),  # Total number of companies\n",
    "    'n_companies_train': len(X_train),  # Companies in training set\n",
    "    'n_companies_test': len(X_test),  # Companies in test set\n",
    "    'model': model,\n",
    "    'y_test': y_test,\n",
    "    'y_pred': y_pred\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sector specific linear model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sector_models(feature_df, score_df, base_columns, yeo_columns, \n",
    "                      LR_Base_random=None, LR_Yeo_random=None,\n",
    "                      model_metrics_dict=None, random_state=42, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Run linear regression models separately for each GICS sector.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    feature_df : pandas.DataFrame\n",
    "        Full feature dataframe\n",
    "    score_df : pandas.Series or DataFrame\n",
    "        Target variable (ESG scores)\n",
    "    base_columns : list\n",
    "        List of base feature columns\n",
    "    yeo_columns : list\n",
    "        List of Yeo-Johnson transformed feature columns\n",
    "    LR_Base_random : pandas.DataFrame, optional\n",
    "        Base dataset with random feature\n",
    "    LR_Yeo_random : pandas.DataFrame, optional\n",
    "        Yeo-Johnson dataset with random feature\n",
    "    model_metrics_dict : dict, optional\n",
    "        Dictionary to store model metrics (will be updated with sector models)\n",
    "    random_state : int, default=42\n",
    "        Reproducibility seed\n",
    "    test_size : float, default=0.2\n",
    "        Proportion of data for testing\n",
    "    \"\"\"\n",
    "    # Create dictionary to store metrics if none provided\n",
    "    if model_metrics_dict is None:\n",
    "        model_metrics_dict = {}\n",
    "    \n",
    "    # Check if random features are provided\n",
    "    use_random_features = (LR_Base_random is not None and LR_Yeo_random is not None)\n",
    "    \n",
    "    # Identify sector columns\n",
    "    sector_columns = [col for col in feature_df.columns if col.startswith('gics_sector_')]\n",
    "    \n",
    "    # Define minimum companies needed per sector for modeling\n",
    "    MIN_COMPANIES = 50\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"Running Linear Regression Models by Sector\")\n",
    "    print(\"=\"*65)\n",
    "    \n",
    "    # For each sector, create and evaluate models\n",
    "    for sector_col in sector_columns:\n",
    "        sector_name = sector_col.replace('gics_sector_', '')\n",
    "        # Filter for companies in this sector\n",
    "        sector_mask = feature_df[sector_col] == 1\n",
    "        X_sector = feature_df[sector_mask]\n",
    "        y_sector = score_df[sector_mask]\n",
    "        \n",
    "        # Check if we have enough companies in this sector\n",
    "        if len(X_sector) < MIN_COMPANIES:\n",
    "            print(f\"\\nSkipping {sector_name} - insufficient data ({len(X_sector)} companies, need {MIN_COMPANIES})\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{sector_name} Sector - {len(X_sector)} companies\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Create feature sets for this sector\n",
    "        X_sector_base = X_sector[base_columns]\n",
    "        X_sector_yeo = X_sector[yeo_columns]\n",
    "        \n",
    "        # For random features, we need to filter the random datasets by the same sector indices\n",
    "        if use_random_features:\n",
    "            # Get the indices of companies in this sector\n",
    "            sector_indices = X_sector.index\n",
    "            \n",
    "            # Filter random datasets to only include companies in this sector\n",
    "            X_sector_base_random = LR_Base_random.loc[sector_indices]\n",
    "            X_sector_yeo_random = LR_Yeo_random.loc[sector_indices]\n",
    "        \n",
    "        # Simple train-test split for regular features\n",
    "        X_train_base, X_test_base, y_train, y_test = train_test_split(\n",
    "            X_sector_base, y_sector, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Use the same indices for the Yeo features\n",
    "        train_indices = X_train_base.index\n",
    "        test_indices = X_test_base.index\n",
    "        X_train_yeo = X_sector_yeo.loc[train_indices]\n",
    "        X_test_yeo = X_sector_yeo.loc[test_indices]\n",
    "        \n",
    "        # If using random features, split them too using the same indices\n",
    "        if use_random_features:\n",
    "            X_train_base_random = X_sector_base_random.loc[train_indices]\n",
    "            X_test_base_random = X_sector_base_random.loc[test_indices]\n",
    "            X_train_yeo_random = X_sector_yeo_random.loc[train_indices]\n",
    "            X_test_yeo_random = X_sector_yeo_random.loc[test_indices]\n",
    "        \n",
    "        # Train and evaluate all model variations\n",
    "        model_configs = [\n",
    "            {'name': f\"Sector_{sector_name}_Base\", 'X_train': X_train_base, 'X_test': X_test_base, 'type': 'Base'}\n",
    "        ]\n",
    "        \n",
    "        # Add Yeo model configuration\n",
    "        model_configs.append(\n",
    "            {'name': f\"Sector_{sector_name}_Yeo\", 'X_train': X_train_yeo, 'X_test': X_test_yeo, 'type': 'Yeo'}\n",
    "        )\n",
    "        \n",
    "        # Add random feature model configurations if available\n",
    "        if use_random_features:\n",
    "            model_configs.append(\n",
    "                {'name': f\"Sector_{sector_name}_Base_Random\", 'X_train': X_train_base_random, 'X_test': X_test_base_random, 'type': 'Base+Random'}\n",
    "            )\n",
    "            model_configs.append(\n",
    "                {'name': f\"Sector_{sector_name}_Yeo_Random\", 'X_train': X_train_yeo_random, 'X_test': X_test_yeo_random, 'type': 'Yeo+Random'}\n",
    "            )\n",
    "        \n",
    "        # Train and evaluate all models\n",
    "        for config in model_configs:\n",
    "            # Train model\n",
    "            model = LinearRegression()\n",
    "            model.fit(config['X_train'], y_train)\n",
    "            y_pred = model.predict(config['X_test'])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            # Store results\n",
    "            model_metrics_dict[config['name']] = {\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'MSE': mse,\n",
    "                'R2': r2,\n",
    "                'n_companies': len(X_sector),  # Total number of companies in this sector\n",
    "                'n_companies_train': len(X_train_base),  # Companies in training set\n",
    "                'n_companies_test': len(X_test_base),  # Companies in test set\n",
    "                'model': model,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'sector': sector_name,\n",
    "                'type': config['type']\n",
    "            }\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"  {config['type']} Model - RMSE: {rmse:.4f}, MAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    \n",
    "    # Print summary of all sector models\n",
    "    print(\"\\n\" + \"=\"*75)\n",
    "    print(\"Summary of Sector-Specific Model Performance\")\n",
    "    print(\"=\"*75)\n",
    "    print(f\"{'Sector':<20} {'Model Type':<15} {'RMSE':<8} {'MAE':<8} {'MSE':<8} {'R²':<8} {'n':<6}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    # Filter for only sector models\n",
    "    sector_models = {k: v for k, v in model_metrics_dict.items() if k.startswith('Sector_')}\n",
    "    \n",
    "    # Print all sector models sorted by sector then type\n",
    "    for sector in sorted(set(v['sector'] for v in sector_models.values())):\n",
    "        sector_specific_models = {k: v for k, v in sector_models.items() if v['sector'] == sector}\n",
    "        for model_name, metrics in sorted(sector_specific_models.items(), \n",
    "                                         key=lambda x: ('Random' in x[0], x[0])):\n",
    "            print(f\"{sector:<20} {metrics['type']:<15} {metrics['RMSE']:.4f}  {metrics['MAE']:.4f}  {metrics['MSE']:.4f}  {metrics['R2']:.4f}  {metrics['n_companies']:<6}\")\n",
    "    \n",
    "    # Calculate and print averages by model type\n",
    "    print(\"\\n\" + \"=\"*75)\n",
    "    print(\"Average Performance by Model Type\")\n",
    "    print(\"=\"*75)\n",
    "    \n",
    "    model_types = set(v['type'] for v in sector_models.values())\n",
    "    \n",
    "    for model_type in sorted(model_types):\n",
    "        models = {k: v for k, v in sector_models.items() if v['type'] == model_type}\n",
    "        if models:\n",
    "            avg_rmse = np.mean([m['RMSE'] for m in models.values()])\n",
    "            avg_mae = np.mean([m['MAE'] for m in models.values()])\n",
    "            avg_mse = np.mean([m['MSE'] for m in models.values()])\n",
    "            avg_r2 = np.mean([m['R2'] for m in models.values()])\n",
    "            print(f\"{model_type:<15} RMSE: {avg_rmse:.4f}, MAE: {avg_mae:.4f}, MSE: {avg_mse:.4f}, R²: {avg_r2:.4f}\")\n",
    "    \n",
    "    return model_metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Running Linear Regression on All Feature Sets\n",
      "==================================================\n",
      "\n",
      "Processing dataset: LR_Base\n",
      "Sector distribution check:\n",
      "Consumer Discretionary: Train 12.2%, Test 11.1%\n",
      "Consumer Staples: Train 7.2%, Test 7.0%\n",
      "Energy: Train 4.4%, Test 4.5%\n",
      "Financials: Train 16.0%, Test 16.1%\n",
      "Health Care: Train 8.9%, Test 8.8%\n",
      "Industrials: Train 20.0%, Test 20.0%\n",
      "Information Technology: Train 10.3%, Test 10.2%\n",
      "Materials: Train 8.6%, Test 8.6%\n",
      "Real Estate: Train 2.4%, Test 2.3%\n",
      "Utilities: Train 4.7%, Test 4.8%\n",
      "\n",
      "Model: LR_Base\n",
      "  RMSE: 1.8645\n",
      "  MAE : 1.4509\n",
      "  MSE : 3.4763\n",
      "  R²  : 0.1066\n",
      "\n",
      "Processing dataset: LR_Yeo\n",
      "Sector distribution check:\n",
      "Consumer Discretionary: Train 12.2%, Test 11.1%\n",
      "Consumer Staples: Train 7.2%, Test 7.0%\n",
      "Energy: Train 4.4%, Test 4.5%\n",
      "Financials: Train 16.0%, Test 16.1%\n",
      "Health Care: Train 8.9%, Test 8.8%\n",
      "Industrials: Train 20.0%, Test 20.0%\n",
      "Information Technology: Train 10.3%, Test 10.2%\n",
      "Materials: Train 8.6%, Test 8.6%\n",
      "Real Estate: Train 2.4%, Test 2.3%\n",
      "Utilities: Train 4.7%, Test 4.8%\n",
      "\n",
      "Model: LR_Yeo\n",
      "  RMSE: 1.9261\n",
      "  MAE : 1.4711\n",
      "  MSE : 3.7098\n",
      "  R²  : 0.0466\n",
      "\n",
      "Processing dataset: LR_Base_Random\n",
      "Sector distribution check:\n",
      "Consumer Discretionary: Train 12.2%, Test 11.1%\n",
      "Consumer Staples: Train 7.2%, Test 7.0%\n",
      "Energy: Train 4.4%, Test 4.5%\n",
      "Financials: Train 16.0%, Test 16.1%\n",
      "Health Care: Train 8.9%, Test 8.8%\n",
      "Industrials: Train 20.0%, Test 20.0%\n",
      "Information Technology: Train 10.3%, Test 10.2%\n",
      "Materials: Train 8.6%, Test 8.6%\n",
      "Real Estate: Train 2.4%, Test 2.3%\n",
      "Utilities: Train 4.7%, Test 4.8%\n",
      "\n",
      "Model: LR_Base_Random\n",
      "  RMSE: 1.8682\n",
      "  MAE : 1.4441\n",
      "  MSE : 3.4901\n",
      "  R²  : 0.1030\n",
      "\n",
      "Processing dataset: LR_Yeo_Random\n",
      "Sector distribution check:\n",
      "Consumer Discretionary: Train 12.2%, Test 11.1%\n",
      "Consumer Staples: Train 7.2%, Test 7.0%\n",
      "Energy: Train 4.4%, Test 4.5%\n",
      "Financials: Train 16.0%, Test 16.1%\n",
      "Health Care: Train 8.9%, Test 8.8%\n",
      "Industrials: Train 20.0%, Test 20.0%\n",
      "Information Technology: Train 10.3%, Test 10.2%\n",
      "Materials: Train 8.6%, Test 8.6%\n",
      "Real Estate: Train 2.4%, Test 2.3%\n",
      "Utilities: Train 4.7%, Test 4.8%\n",
      "\n",
      "Model: LR_Yeo_Random\n",
      "  RMSE: 1.9279\n",
      "  MAE : 1.4725\n",
      "  MSE : 3.7167\n",
      "  R²  : 0.0448\n",
      "\n",
      "=================================================================\n",
      "Running Linear Regression Models by Sector\n",
      "=================================================================\n",
      "\n",
      "Consumer Discretionary Sector - 264 companies\n",
      "--------------------------------------------------\n",
      "  Base Model - RMSE: 2.9847, MAE: 2.2767, MSE: 8.9085, R²: -0.8174\n",
      "  Yeo Model - RMSE: 3.0751, MAE: 2.3827, MSE: 9.4561, R²: -0.9292\n",
      "  Base+Random Model - RMSE: 3.1421, MAE: 2.4484, MSE: 9.8728, R²: -1.0142\n",
      "  Yeo+Random Model - RMSE: 3.0745, MAE: 2.3829, MSE: 9.4527, R²: -0.9285\n",
      "\n",
      "Consumer Staples Sector - 157 companies\n",
      "--------------------------------------------------\n",
      "  Base Model - RMSE: 2.5190, MAE: 2.0702, MSE: 6.3453, R²: -0.8791\n",
      "  Yeo Model - RMSE: 2.1843, MAE: 1.8551, MSE: 4.7712, R²: -0.4129\n",
      "  Base+Random Model - RMSE: 2.4954, MAE: 2.0429, MSE: 6.2270, R²: -0.8440\n",
      "  Yeo+Random Model - RMSE: 2.1721, MAE: 1.8488, MSE: 4.7181, R²: -0.3972\n",
      "\n",
      "Energy Sector - 98 companies\n",
      "--------------------------------------------------\n",
      "  Base Model - RMSE: 4.8482, MAE: 4.0401, MSE: 23.5047, R²: -2.3631\n",
      "  Yeo Model - RMSE: 5.3913, MAE: 4.1569, MSE: 29.0663, R²: -3.1589\n",
      "  Base+Random Model - RMSE: 5.5128, MAE: 4.4204, MSE: 30.3904, R²: -3.3484\n",
      "  Yeo+Random Model - RMSE: 5.5256, MAE: 4.4372, MSE: 30.5326, R²: -3.3687\n",
      "\n",
      "Financials Sector - 352 companies\n",
      "--------------------------------------------------\n",
      "  Base Model - RMSE: 2.1981, MAE: 1.7535, MSE: 4.8317, R²: -0.2620\n",
      "  Yeo Model - RMSE: 1.8393, MAE: 1.4918, MSE: 3.3829, R²: 0.1164\n",
      "  Base+Random Model - RMSE: 2.1907, MAE: 1.7497, MSE: 4.7991, R²: -0.2535\n",
      "  Yeo+Random Model - RMSE: 1.8564, MAE: 1.4847, MSE: 3.4461, R²: 0.0999\n",
      "\n",
      "Health Care Sector - 195 companies\n",
      "--------------------------------------------------\n",
      "  Base Model - RMSE: 3.2725, MAE: 2.4113, MSE: 10.7091, R²: -1.7789\n",
      "  Yeo Model - RMSE: 2.9278, MAE: 2.1345, MSE: 8.5718, R²: -1.2243\n",
      "  Base+Random Model - RMSE: 3.1837, MAE: 2.4425, MSE: 10.1361, R²: -1.6302\n",
      "  Yeo+Random Model - RMSE: 2.8935, MAE: 2.1345, MSE: 8.3725, R²: -1.1726\n",
      "\n",
      "Industrials Sector - 440 companies\n",
      "--------------------------------------------------\n",
      "  Base Model - RMSE: 2.0162, MAE: 1.5444, MSE: 4.0650, R²: -0.7291\n",
      "  Yeo Model - RMSE: 2.0124, MAE: 1.4944, MSE: 4.0499, R²: -0.7227\n",
      "  Base+Random Model - RMSE: 2.0274, MAE: 1.5440, MSE: 4.1103, R²: -0.7484\n",
      "  Yeo+Random Model - RMSE: 2.0524, MAE: 1.5262, MSE: 4.2124, R²: -0.7918\n",
      "\n",
      "Information Technology Sector - 227 companies\n",
      "--------------------------------------------------\n",
      "  Base Model - RMSE: 2.2975, MAE: 1.8322, MSE: 5.2786, R²: -0.5830\n",
      "  Yeo Model - RMSE: 2.0408, MAE: 1.6879, MSE: 4.1648, R²: -0.2490\n",
      "  Base+Random Model - RMSE: 2.2683, MAE: 1.8594, MSE: 5.1453, R²: -0.5430\n",
      "  Yeo+Random Model - RMSE: 2.0055, MAE: 1.6281, MSE: 4.0220, R²: -0.2062\n",
      "\n",
      "Materials Sector - 190 companies\n",
      "--------------------------------------------------\n",
      "  Base Model - RMSE: 2.0639, MAE: 1.7101, MSE: 4.2597, R²: -0.0976\n",
      "  Yeo Model - RMSE: 3.6335, MAE: 2.2958, MSE: 13.2026, R²: -2.4020\n",
      "  Base+Random Model - RMSE: 2.0580, MAE: 1.7342, MSE: 4.2354, R²: -0.0913\n",
      "  Yeo+Random Model - RMSE: 3.7236, MAE: 2.3214, MSE: 13.8653, R²: -2.5727\n",
      "\n",
      "Real Estate Sector - 52 companies\n",
      "--------------------------------------------------\n",
      "  Base Model - RMSE: 7.5165, MAE: 4.7104, MSE: 56.4979, R²: -9.7212\n",
      "  Yeo Model - RMSE: 7.8142, MAE: 6.6426, MSE: 61.0610, R²: -10.5871\n",
      "  Base+Random Model - RMSE: 6.2008, MAE: 4.1533, MSE: 38.4502, R²: -6.2964\n",
      "  Yeo+Random Model - RMSE: 7.6609, MAE: 6.6514, MSE: 58.6891, R²: -10.1370\n",
      "\n",
      "Utilities Sector - 103 companies\n",
      "--------------------------------------------------\n",
      "  Base Model - RMSE: 4.3495, MAE: 3.5316, MSE: 18.9179, R²: -7.1127\n",
      "  Yeo Model - RMSE: 4.8120, MAE: 3.3458, MSE: 23.1556, R²: -8.9300\n",
      "  Base+Random Model - RMSE: 3.9222, MAE: 3.3142, MSE: 15.3834, R²: -5.5970\n",
      "  Yeo+Random Model - RMSE: 4.6162, MAE: 3.4387, MSE: 21.3095, R²: -8.1383\n",
      "\n",
      "===========================================================================\n",
      "Summary of Sector-Specific Model Performance\n",
      "===========================================================================\n",
      "Sector               Model Type      RMSE     MAE      MSE      R²       n     \n",
      "---------------------------------------------------------------------------\n",
      "Consumer Discretionary Base            2.9847  2.2767  8.9085  -0.8174  264   \n",
      "Consumer Discretionary Yeo             3.0751  2.3827  9.4561  -0.9292  264   \n",
      "Consumer Discretionary Base+Random     3.1421  2.4484  9.8728  -1.0142  264   \n",
      "Consumer Discretionary Yeo+Random      3.0745  2.3829  9.4527  -0.9285  264   \n",
      "Consumer Staples     Base            2.5190  2.0702  6.3453  -0.8791  157   \n",
      "Consumer Staples     Yeo             2.1843  1.8551  4.7712  -0.4129  157   \n",
      "Consumer Staples     Base+Random     2.4954  2.0429  6.2270  -0.8440  157   \n",
      "Consumer Staples     Yeo+Random      2.1721  1.8488  4.7181  -0.3972  157   \n",
      "Energy               Base            4.8482  4.0401  23.5047  -2.3631  98    \n",
      "Energy               Yeo             5.3913  4.1569  29.0663  -3.1589  98    \n",
      "Energy               Base+Random     5.5128  4.4204  30.3904  -3.3484  98    \n",
      "Energy               Yeo+Random      5.5256  4.4372  30.5326  -3.3687  98    \n",
      "Financials           Base            2.1981  1.7535  4.8317  -0.2620  352   \n",
      "Financials           Yeo             1.8393  1.4918  3.3829  0.1164  352   \n",
      "Financials           Base+Random     2.1907  1.7497  4.7991  -0.2535  352   \n",
      "Financials           Yeo+Random      1.8564  1.4847  3.4461  0.0999  352   \n",
      "Health Care          Base            3.2725  2.4113  10.7091  -1.7789  195   \n",
      "Health Care          Yeo             2.9278  2.1345  8.5718  -1.2243  195   \n",
      "Health Care          Base+Random     3.1837  2.4425  10.1361  -1.6302  195   \n",
      "Health Care          Yeo+Random      2.8935  2.1345  8.3725  -1.1726  195   \n",
      "Industrials          Base            2.0162  1.5444  4.0650  -0.7291  440   \n",
      "Industrials          Yeo             2.0124  1.4944  4.0499  -0.7227  440   \n",
      "Industrials          Base+Random     2.0274  1.5440  4.1103  -0.7484  440   \n",
      "Industrials          Yeo+Random      2.0524  1.5262  4.2124  -0.7918  440   \n",
      "Information Technology Base            2.2975  1.8322  5.2786  -0.5830  227   \n",
      "Information Technology Yeo             2.0408  1.6879  4.1648  -0.2490  227   \n",
      "Information Technology Base+Random     2.2683  1.8594  5.1453  -0.5430  227   \n",
      "Information Technology Yeo+Random      2.0055  1.6281  4.0220  -0.2062  227   \n",
      "Materials            Base            2.0639  1.7101  4.2597  -0.0976  190   \n",
      "Materials            Yeo             3.6335  2.2958  13.2026  -2.4020  190   \n",
      "Materials            Base+Random     2.0580  1.7342  4.2354  -0.0913  190   \n",
      "Materials            Yeo+Random      3.7236  2.3214  13.8653  -2.5727  190   \n",
      "Real Estate          Base            7.5165  4.7104  56.4979  -9.7212  52    \n",
      "Real Estate          Yeo             7.8142  6.6426  61.0610  -10.5871  52    \n",
      "Real Estate          Base+Random     6.2008  4.1533  38.4502  -6.2964  52    \n",
      "Real Estate          Yeo+Random      7.6609  6.6514  58.6891  -10.1370  52    \n",
      "Utilities            Base            4.3495  3.5316  18.9179  -7.1127  103   \n",
      "Utilities            Yeo             4.8120  3.3458  23.1556  -8.9300  103   \n",
      "Utilities            Base+Random     3.9222  3.3142  15.3834  -5.5970  103   \n",
      "Utilities            Yeo+Random      4.6162  3.4387  21.3095  -8.1383  103   \n",
      "\n",
      "===========================================================================\n",
      "Average Performance by Model Type\n",
      "===========================================================================\n",
      "Base            RMSE: 3.4066, MAE: 2.5880, MSE: 14.3318, R²: -2.4344\n",
      "Base+Random     RMSE: 3.3001, MAE: 2.5709, MSE: 12.8750, R²: -2.0366\n",
      "Yeo             RMSE: 3.5731, MAE: 2.7488, MSE: 16.0882, R²: -2.8500\n",
      "Yeo+Random      RMSE: 3.5581, MAE: 2.7854, MSE: 15.8620, R²: -2.7613\n",
      "\n",
      "=================================================================\n",
      "Overall Best Models Comparison\n",
      "=================================================================\n",
      "Best Models:\n",
      "  Best Global: LR_Base (RMSE: 1.8645, R²: 0.1066)\n",
      "  Best Sector: Sector_Financials_Yeo (RMSE: 1.8393, R²: 0.1164)\n",
      "  Improvement: RMSE 0.0252, R² 0.0098\n",
      "CPU times: user 37 s, sys: 71.9 ms, total: 37.1 s\n",
      "Wall time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize a dictionary to store all model metrics\n",
    "model_metrics = {}\n",
    "\n",
    "# Run All Models and Compare Performance\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Running Linear Regression on All Feature Sets\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define all datasets to use\n",
    "dataset_configs = [\n",
    "    {'data': LR_Base, 'name': 'LR_Base'},\n",
    "    {'data': LR_Yeo, 'name': 'LR_Yeo'},\n",
    "    {'data': LR_Base_random, 'name': 'LR_Base_Random'},\n",
    "    {'data': LR_Yeo_random, 'name': 'LR_Yeo_Random'}\n",
    "]\n",
    "\n",
    "# Run regression on each dataset\n",
    "for config in dataset_configs:\n",
    "    print(f\"\\nProcessing dataset: {config['name']}\")\n",
    "    run_regression_model(config['data'], y, model_name=config['name'])\n",
    "\n",
    "# Now run the sector-specific models with random features\n",
    "run_sector_models(\n",
    "    feature_df, \n",
    "    score_df, \n",
    "    base_columns, \n",
    "    yeo_columns,\n",
    "    LR_Base_random=LR_Base_random,  # Pass the entire random datasets\n",
    "    LR_Yeo_random=LR_Yeo_random,\n",
    "    model_metrics_dict=model_metrics\n",
    ")\n",
    "\n",
    "# Print overall comparison\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"Overall Best Models Comparison\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Group models by type\n",
    "global_models = {k: v for k, v in model_metrics.items() if not k.startswith('Sector_')}\n",
    "sector_models = {k: v for k, v in model_metrics.items() if k.startswith('Sector_')}\n",
    "\n",
    "# Find best models\n",
    "best_global = min(global_models.items(), key=lambda x: x[1]['RMSE']) if global_models else (None, {})\n",
    "best_sector = min(sector_models.items(), key=lambda x: x[1]['RMSE']) if sector_models else (None, {})\n",
    "\n",
    "print(\"Best Models:\")\n",
    "if best_global[0]:\n",
    "    print(f\"  Best Global: {best_global[0]} (RMSE: {best_global[1]['RMSE']:.4f}, R²: {best_global[1]['R2']:.4f})\")\n",
    "if best_sector[0]:\n",
    "    print(f\"  Best Sector: {best_sector[0]} (RMSE: {best_sector[1]['RMSE']:.4f}, R²: {best_sector[1]['R2']:.4f})\")\n",
    "    \n",
    "if best_global[0] and best_sector[0]:\n",
    "    print(f\"  Improvement: RMSE {(best_global[1]['RMSE'] - best_sector[1]['RMSE']):.4f}, R² {(best_sector[1]['R2'] - best_global[1]['R2']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('strat_linreg_eval_metrics/model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(model_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'model_name': name,\n",
    "        'RMSE': metrics['RMSE'],\n",
    "        'MAE': metrics['MAE'],\n",
    "        'MSE': metrics['MSE'],\n",
    "        'R2': metrics['R2'],\n",
    "        'is_sector_model': name.startswith('Sector_'),\n",
    "        'sector': metrics.get('sector', 'Global'),\n",
    "        'type': metrics.get('type', 'Global'),\n",
    "        'n_companies': metrics.get('n_companies', 0),  # Add number of companies\n",
    "        'n_companies_train': metrics.get('n_companies_train', 0),  # Training set size\n",
    "        'n_companies_test': metrics.get('n_companies_test', 0)  # Test set size\n",
    "    }\n",
    "    for name, metrics in model_metrics.items()\n",
    "])\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('strat_linreg_eval_metrics/model_comparison_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Elastic net tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Finding Optimal ElasticNet Parameters for All Datasets with Stratified Splitting\n",
      "==================================================\n",
      "\n",
      "Processing dataset: LR_Base...\n",
      "  Sector distribution in train/test sets:\n",
      "    Consumer Discretionary: Train 17.6%, Test 17.7%\n",
      "    Consumer Staples: Train 7.2%, Test 7.0%\n",
      "    Energy: Train 4.4%, Test 4.5%\n",
      "    Financials: Train 16.0%, Test 16.1%\n",
      "    Health Care: Train 8.9%, Test 8.8%\n",
      "    Industrials: Train 20.0%, Test 20.0%\n",
      "    Information Technology: Train 10.3%, Test 10.2%\n",
      "    Materials: Train 8.6%, Test 8.6%\n",
      "    Real Estate: Train 2.4%, Test 2.3%\n",
      "    Utilities: Train 4.7%, Test 4.8%\n",
      "Dataset: LR_Base\n",
      "  → Least CV RMSE: 1.9162\n",
      "  → Best parameters (alpha, l1_ratio): (np.float64(1.5848931924611136), np.float64(1.0))\n",
      "  → Number of companies: 2202 (train: 1761, test: 441)\n",
      "\n",
      "Processing dataset: LR_Yeo...\n",
      "  Sector distribution in train/test sets:\n",
      "    Consumer Discretionary: Train 17.6%, Test 17.7%\n",
      "    Consumer Staples: Train 7.2%, Test 7.0%\n",
      "    Energy: Train 4.4%, Test 4.5%\n",
      "    Financials: Train 16.0%, Test 16.1%\n",
      "    Health Care: Train 8.9%, Test 8.8%\n",
      "    Industrials: Train 20.0%, Test 20.0%\n",
      "    Information Technology: Train 10.3%, Test 10.2%\n",
      "    Materials: Train 8.6%, Test 8.6%\n",
      "    Real Estate: Train 2.4%, Test 2.3%\n",
      "    Utilities: Train 4.7%, Test 4.8%\n",
      "Dataset: LR_Yeo\n",
      "  → Least CV RMSE: 1.7120\n",
      "  → Best parameters (alpha, l1_ratio): (np.float64(0.1), np.float64(0.0))\n",
      "  → Number of companies: 2202 (train: 1761, test: 441)\n",
      "\n",
      "Processing dataset: LR_Base_random...\n",
      "  Sector distribution in train/test sets:\n",
      "    Consumer Discretionary: Train 17.6%, Test 17.7%\n",
      "    Consumer Staples: Train 7.2%, Test 7.0%\n",
      "    Energy: Train 4.4%, Test 4.5%\n",
      "    Financials: Train 16.0%, Test 16.1%\n",
      "    Health Care: Train 8.9%, Test 8.8%\n",
      "    Industrials: Train 20.0%, Test 20.0%\n",
      "    Information Technology: Train 10.3%, Test 10.2%\n",
      "    Materials: Train 8.6%, Test 8.6%\n",
      "    Real Estate: Train 2.4%, Test 2.3%\n",
      "    Utilities: Train 4.7%, Test 4.8%\n",
      "Dataset: LR_Base_random\n",
      "  → Least CV RMSE: 1.9162\n",
      "  → Best parameters (alpha, l1_ratio): (np.float64(1.5848931924611136), np.float64(1.0))\n",
      "  → Number of companies: 2202 (train: 1761, test: 441)\n",
      "\n",
      "Processing dataset: LR_Yeo_random...\n",
      "  Sector distribution in train/test sets:\n",
      "    Consumer Discretionary: Train 17.6%, Test 17.7%\n",
      "    Consumer Staples: Train 7.2%, Test 7.0%\n",
      "    Energy: Train 4.4%, Test 4.5%\n",
      "    Financials: Train 16.0%, Test 16.1%\n",
      "    Health Care: Train 8.9%, Test 8.8%\n",
      "    Industrials: Train 20.0%, Test 20.0%\n",
      "    Information Technology: Train 10.3%, Test 10.2%\n",
      "    Materials: Train 8.6%, Test 8.6%\n",
      "    Real Estate: Train 2.4%, Test 2.3%\n",
      "    Utilities: Train 4.7%, Test 4.8%\n",
      "Dataset: LR_Yeo_random\n",
      "  → Least CV RMSE: 1.7128\n",
      "  → Best parameters (alpha, l1_ratio): (np.float64(0.1), np.float64(0.0))\n",
      "  → Number of companies: 2202 (train: 1761, test: 441)\n",
      "\n",
      "==================================================\n",
      "Summary of Best ElasticNet Parameters per Dataset\n",
      "==================================================\n",
      "LR_Base: RMSE = 1.9162, Best Params = (np.float64(1.5848931924611136), np.float64(1.0)), Companies = 2202\n",
      "LR_Yeo: RMSE = 1.7120, Best Params = (np.float64(0.1), np.float64(0.0)), Companies = 2202\n",
      "LR_Base_random: RMSE = 1.9162, Best Params = (np.float64(1.5848931924611136), np.float64(1.0)), Companies = 2202\n",
      "LR_Yeo_random: RMSE = 1.7128, Best Params = (np.float64(0.1), np.float64(0.0)), Companies = 2202\n",
      "\n",
      "ElasticNet parameters saved to 'strat_linreg_eval_metrics/elasticnet_stratified_params.pkl'\n",
      "CPU times: user 6h 9min 53s, sys: 5.28 s, total: 6h 9min 58s\n",
      "Wall time: 23min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Finding Optimal ElasticNet Parameters for All Datasets with Stratified Splitting\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Hyperparameter grid\n",
    "lamb = 10 ** np.linspace(-1, 0.2, 15)  # Regularization strengths (alpha)\n",
    "ratio = np.linspace(0, 1, 10)          # L1/L2 mixing (l1_ratio)\n",
    "\n",
    "# All datasets and target\n",
    "datasets = [LR_Base, LR_Yeo, LR_Base_random, LR_Yeo_random]\n",
    "dataset_names = ['LR_Base', 'LR_Yeo', 'LR_Base_random', 'LR_Yeo_random']\n",
    "target = score_df\n",
    "\n",
    "# Storage for results\n",
    "results_summary = []\n",
    "\n",
    "# Iterate through datasets\n",
    "for idx, X in enumerate(datasets):\n",
    "    print(f\"\\nProcessing dataset: {dataset_names[idx]}...\")\n",
    "    \n",
    "    # Extract sector information for stratification\n",
    "    sector_columns = [col for col in X.columns if col.startswith('gics_sector_')]\n",
    "    sector_data = X[sector_columns].copy()\n",
    "    sector_labels = np.zeros(len(X), dtype=int)\n",
    "    \n",
    "    for i, col in enumerate(sector_columns):\n",
    "        sector_labels[sector_data[col] == 1] = i\n",
    "    \n",
    "    # Split into train/test using stratification\n",
    "    X_train, X_test, y_train, y_test, sector_train, sector_test = train_test_split(\n",
    "        X, target, sector_labels, test_size=0.2, random_state=42, stratify=sector_labels\n",
    "    )\n",
    "\n",
    "    # Verify sector distribution\n",
    "    print(\"  Sector distribution in train/test sets:\")\n",
    "    for i, col in enumerate(sector_columns):\n",
    "        sector_name = col.replace('gics_sector_', '')\n",
    "        train_pct = np.mean(sector_train == i) * 100\n",
    "        test_pct = np.mean(sector_test == i) * 100\n",
    "        print(f\"    {sector_name}: Train {train_pct:.1f}%, Test {test_pct:.1f}%\")\n",
    "    \n",
    "    # Create stratified k-fold for cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Grid search with stratified cross-validation\n",
    "    get_results = []\n",
    "    \n",
    "    for la in lamb:\n",
    "        for r in ratio:\n",
    "            # Wrap in try-except to handle any issues\n",
    "            try:\n",
    "                # Initialize scores collection\n",
    "                rmse_folds = []\n",
    "                \n",
    "                # Manually perform stratified cross-validation\n",
    "                for train_idx, val_idx in skf.split(X_train, sector_train):\n",
    "                    # Create train/validation splits while preserving sector proportions\n",
    "                    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "                    \n",
    "                    # Train model\n",
    "                    model = ElasticNet(alpha=la, l1_ratio=r, random_state=42, max_iter=10000)\n",
    "                    model.fit(X_fold_train, y_fold_train)\n",
    "                    \n",
    "                    # Predict and calculate RMSE\n",
    "                    y_pred = model.predict(X_fold_val)\n",
    "                    mse = mean_squared_error(y_fold_val, y_pred)\n",
    "                    rmse = np.sqrt(mse)\n",
    "                    rmse_folds.append(rmse)\n",
    "                \n",
    "                # Calculate mean RMSE across folds\n",
    "                mean_rmse = np.mean(rmse_folds)\n",
    "                get_results.append((la, r, mean_rmse, rmse_folds))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Error with alpha={la}, l1_ratio={r}: {str(e)}\")\n",
    "\n",
    "    # Extract best results if we have any\n",
    "    if get_results:\n",
    "        # Find the result with minimum RMSE\n",
    "        best_result = min(get_results, key=lambda x: x[2])  # x[2] is mean_rmse\n",
    "        best_alpha, best_l1_ratio, least_error, best_rmse_folds = best_result\n",
    "\n",
    "        # Save results\n",
    "        results_summary.append({\n",
    "            'dataset': dataset_names[idx],\n",
    "            'least_error': least_error,\n",
    "            'best_params': (best_alpha, best_l1_ratio),\n",
    "            'rmse_folds': best_rmse_folds,\n",
    "            'n_companies': len(X),\n",
    "            'n_companies_train': len(X_train),\n",
    "            'n_companies_test': len(X_test)\n",
    "        })\n",
    "\n",
    "        # Print intermediate results\n",
    "        print(f'Dataset: {dataset_names[idx]}')\n",
    "        print(f'  → Least CV RMSE: {least_error:.4f}')\n",
    "        print(f'  → Best parameters (alpha, l1_ratio): {(best_alpha, best_l1_ratio)}')\n",
    "        print(f'  → Number of companies: {len(X)} (train: {len(X_train)}, test: {len(X_test)})')\n",
    "\n",
    "    else:\n",
    "        print(f\"  No valid results for {dataset_names[idx]}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Summary of Best ElasticNet Parameters per Dataset\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for res in results_summary:\n",
    "    print(f\"{res['dataset']}: RMSE = {res['least_error']:.4f}, Best Params = {res['best_params']}, Companies = {res['n_companies']}\")\n",
    "\n",
    "# Save results to file\n",
    "with open('strat_linreg_eval_metrics/elasticnet_stratified_params.pkl', 'wb') as f:\n",
    "    pickle.dump(results_summary, f)\n",
    "print(\"\\nElasticNet parameters saved to 'strat_linreg_eval_metrics/elasticnet_stratified_params.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 run models with optimized elastic net parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Running ElasticNet Models with Optimal Parameters\n",
      "==================================================\n",
      "Loaded optimal parameters:\n",
      "  LR_Base: alpha=1.584893, l1_ratio=1.000000\n",
      "  LR_Yeo: alpha=0.100000, l1_ratio=0.000000\n",
      "  LR_Base_random: alpha=1.584893, l1_ratio=1.000000\n",
      "  LR_Yeo_random: alpha=0.100000, l1_ratio=0.000000\n",
      "Sector distribution check:\n",
      "Consumer Discretionary: Train 12.2%, Test 11.1%\n",
      "Consumer Staples: Train 7.2%, Test 7.0%\n",
      "Energy: Train 4.4%, Test 4.5%\n",
      "Financials: Train 16.0%, Test 16.1%\n",
      "Health Care: Train 8.9%, Test 8.8%\n",
      "Industrials: Train 20.0%, Test 20.0%\n",
      "Information Technology: Train 10.3%, Test 10.2%\n",
      "Materials: Train 8.6%, Test 8.6%\n",
      "Real Estate: Train 2.4%, Test 2.3%\n",
      "Utilities: Train 4.7%, Test 4.8%\n",
      "\n",
      "Model: ElasticNet_LR_Base\n",
      "  RMSE: 1.9610\n",
      "  MAE : 1.5514\n",
      "  MSE : 3.8453\n",
      "  R²  : 0.0118\n",
      "  Parameters: alpha=1.584893, l1_ratio=1.000000\n",
      "  Features used: 14 out of 362\n",
      "Sector distribution check:\n",
      "Consumer Discretionary: Train 12.2%, Test 11.1%\n",
      "Consumer Staples: Train 7.2%, Test 7.0%\n",
      "Energy: Train 4.4%, Test 4.5%\n",
      "Financials: Train 16.0%, Test 16.1%\n",
      "Health Care: Train 8.9%, Test 8.8%\n",
      "Industrials: Train 20.0%, Test 20.0%\n",
      "Information Technology: Train 10.3%, Test 10.2%\n",
      "Materials: Train 8.6%, Test 8.6%\n",
      "Real Estate: Train 2.4%, Test 2.3%\n",
      "Utilities: Train 4.7%, Test 4.8%\n",
      "\n",
      "Model: ElasticNet_LR_Yeo\n",
      "  RMSE: 1.7783\n",
      "  MAE : 1.4154\n",
      "  MSE : 3.1624\n",
      "  R²  : 0.1873\n",
      "  Parameters: alpha=0.100000, l1_ratio=0.000000\n",
      "  Features used: 356 out of 362\n",
      "Sector distribution check:\n",
      "Consumer Discretionary: Train 12.2%, Test 11.1%\n",
      "Consumer Staples: Train 7.2%, Test 7.0%\n",
      "Energy: Train 4.4%, Test 4.5%\n",
      "Financials: Train 16.0%, Test 16.1%\n",
      "Health Care: Train 8.9%, Test 8.8%\n",
      "Industrials: Train 20.0%, Test 20.0%\n",
      "Information Technology: Train 10.3%, Test 10.2%\n",
      "Materials: Train 8.6%, Test 8.6%\n",
      "Real Estate: Train 2.4%, Test 2.3%\n",
      "Utilities: Train 4.7%, Test 4.8%\n",
      "\n",
      "Model: ElasticNet_LR_Base_Random\n",
      "  RMSE: 1.9610\n",
      "  MAE : 1.5514\n",
      "  MSE : 3.8453\n",
      "  R²  : 0.0118\n",
      "  Parameters: alpha=1.584893, l1_ratio=1.000000\n",
      "  Features used: 14 out of 363\n",
      "Sector distribution check:\n",
      "Consumer Discretionary: Train 12.2%, Test 11.1%\n",
      "Consumer Staples: Train 7.2%, Test 7.0%\n",
      "Energy: Train 4.4%, Test 4.5%\n",
      "Financials: Train 16.0%, Test 16.1%\n",
      "Health Care: Train 8.9%, Test 8.8%\n",
      "Industrials: Train 20.0%, Test 20.0%\n",
      "Information Technology: Train 10.3%, Test 10.2%\n",
      "Materials: Train 8.6%, Test 8.6%\n",
      "Real Estate: Train 2.4%, Test 2.3%\n",
      "Utilities: Train 4.7%, Test 4.8%\n",
      "\n",
      "Model: ElasticNet_LR_Yeo_Random\n",
      "  RMSE: 1.7783\n",
      "  MAE : 1.4161\n",
      "  MSE : 3.1623\n",
      "  R²  : 0.1873\n",
      "  Parameters: alpha=0.100000, l1_ratio=0.000000\n",
      "  Features used: 357 out of 363\n",
      "\n",
      "==================================================\n",
      "Updating Results DataFrame with ElasticNet Models\n",
      "==================================================\n",
      "Results saved to 'strat_linreg_eval_metrics/model_comparison_results_with_elasticnet.csv'\n",
      "\n",
      "Top 5 models by RMSE:\n",
      "  ElasticNet_LR_Yeo_Random: RMSE = 1.7783, R² = 0.1873, Type = ElasticNet\n",
      "  ElasticNet_LR_Yeo: RMSE = 1.7783, R² = 0.1873, Type = ElasticNet\n",
      "  Sector_Financials_Yeo: RMSE = 1.8393, R² = 0.1164, Type = Yeo\n",
      "  Sector_Financials_Yeo_Random: RMSE = 1.8564, R² = 0.0999, Type = Yeo+Random\n",
      "  LR_Base: RMSE = 1.8645, R² = 0.1066, Type = Global\n",
      "Updated model_metrics saved to 'strat_linreg_eval_metrics/model_results.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Run ElasticNet models with optimal parameters from search\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Running ElasticNet Models with Optimal Parameters\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load the optimal parameters from file\n",
    "try:\n",
    "    with open('strat_linreg_eval_metrics/elasticnet_stratified_params.pkl', 'rb') as f:\n",
    "        elasticnet_results = pickle.load(f)\n",
    "    \n",
    "    # Convert results to a dictionary for easier access\n",
    "    params_dict = {res['dataset']: res for res in elasticnet_results}\n",
    "    \n",
    "    print(\"Loaded optimal parameters:\")\n",
    "    for dataset, res in params_dict.items():\n",
    "        print(f\"  {dataset}: alpha={res['best_params'][0]:.6f}, l1_ratio={res['best_params'][1]:.6f}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Parameter file not found. Run parameter search first.\")\n",
    "    # Define default parameters if file is not found\n",
    "    params_dict = {\n",
    "        'LR_Base': {'best_params': (0.1, 0.0)},\n",
    "        'LR_Yeo': {'best_params': (0.1, 0.0)},\n",
    "        'LR_Base_random': {'best_params': (0.1, 0.0)},\n",
    "        'LR_Yeo_random': {'best_params': (0.1, 0.0)}\n",
    "    }\n",
    "# Save the consolidated model_metrics containing both linear regression and ElasticNet results\n",
    "with open('strat_linreg_eval_metrics/model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(model_metrics, f)\n",
    "\n",
    "# Define datasets to process\n",
    "dataset_configs = [\n",
    "    {'data': LR_Base, 'name': 'ElasticNet_LR_Base', 'param_key': 'LR_Base'},\n",
    "    {'data': LR_Yeo, 'name': 'ElasticNet_LR_Yeo', 'param_key': 'LR_Yeo'},\n",
    "    {'data': LR_Base_random, 'name': 'ElasticNet_LR_Base_Random', 'param_key': 'LR_Base_random'},\n",
    "    {'data': LR_Yeo_random, 'name': 'ElasticNet_LR_Yeo_Random', 'param_key': 'LR_Yeo_random'}\n",
    "]\n",
    "\n",
    "# Function to run ElasticNet with stratified splitting\n",
    "def run_elasticnet_model_stratified(X_data, y_data, model_name, param_key,\n",
    "                                  random_state=42, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Run ElasticNet regression with stratified splitting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_data : pandas.DataFrame\n",
    "        Feature data\n",
    "    y_data : pandas.Series or DataFrame\n",
    "        Target variable\n",
    "    model_name : str\n",
    "        Identifier for the model\n",
    "    param_key : str\n",
    "        Key to lookup parameters in params_dict\n",
    "    random_state : int, default=42\n",
    "        Random seed\n",
    "    test_size : float, default=0.2\n",
    "        Test set proportion\n",
    "    \"\"\"\n",
    "    # Get optimal parameters\n",
    "    alpha, l1_ratio = params_dict[param_key]['best_params']\n",
    "    \n",
    "    # Use stratified split by sector\n",
    "    X_train, X_test, y_train, y_test = perform_stratified_split_by_sector(\n",
    "        X_data, y_data, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Initialize and train model\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=random_state, max_iter=10000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Log results\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE : {mae:.4f}\")\n",
    "    print(f\"  MSE : {mse:.4f}\")\n",
    "    print(f\"  R²  : {r2:.4f}\")\n",
    "    print(f\"  Parameters: alpha={alpha:.6f}, l1_ratio={l1_ratio:.6f}\")\n",
    "\n",
    "    # Count non-zero coefficients to assess feature selection\n",
    "    n_features_used = np.sum(model.coef_ != 0)\n",
    "    print(f\"  Features used: {n_features_used} out of {len(X_data.columns)}\")\n",
    "\n",
    "    # Store metrics in the global dictionary\n",
    "    model_metrics[model_name] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "        'n_companies': len(X_data),\n",
    "        'n_companies_train': len(X_train),\n",
    "        'n_companies_test': len(X_test),\n",
    "        'model': model,\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'type': 'ElasticNet',\n",
    "        'alpha': alpha,\n",
    "        'l1_ratio': l1_ratio,\n",
    "        'n_features_used': n_features_used\n",
    "    }\n",
    "\n",
    "# Run models\n",
    "for config in dataset_configs:\n",
    "    run_elasticnet_model_stratified(\n",
    "        config['data'], \n",
    "        y, \n",
    "        config['name'], \n",
    "        config['param_key']  # Use the explicit param_key instead of derived one\n",
    "    )\n",
    "\n",
    "# Update results DataFrame with ElasticNet models\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Updating Results DataFrame with ElasticNet Models\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'model_name': name,\n",
    "        'RMSE': metrics['RMSE'],\n",
    "        'MAE': metrics['MAE'],\n",
    "        'MSE': metrics['MSE'],\n",
    "        'R2': metrics['R2'],\n",
    "        'is_sector_model': name.startswith('Sector_'),\n",
    "        'sector': metrics.get('sector', 'Global'),\n",
    "        'type': metrics.get('type', 'Global'),\n",
    "        'n_companies': metrics.get('n_companies', 0),\n",
    "        'n_companies_train': metrics.get('n_companies_train', 0),\n",
    "        'n_companies_test': metrics.get('n_companies_test', 0),\n",
    "        'alpha': metrics.get('alpha', None),\n",
    "        'l1_ratio': metrics.get('l1_ratio', None),\n",
    "        'n_features_used': metrics.get('n_features_used', None)\n",
    "    }\n",
    "    for name, metrics in model_metrics.items()\n",
    "])\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('strat_linreg_eval_metrics/model_comparison_results_with_elasticnet.csv', index=False)\n",
    "print(\"Results saved to 'strat_linreg_eval_metrics/model_comparison_results_with_elasticnet.csv'\")\n",
    "\n",
    "# Print summary of best models\n",
    "print(\"\\nTop 5 models by RMSE:\")\n",
    "top_models = results_df.sort_values('RMSE').head(5)\n",
    "for _, row in top_models.iterrows():\n",
    "    print(f\"  {row['model_name']}: RMSE = {row['RMSE']:.4f}, R² = {row['R2']:.4f}, Type = {row['type']}\")\n",
    "\n",
    "# Save the updated model_metrics with ElasticNet models\n",
    "with open('strat_linreg_eval_metrics/model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(model_metrics, f)\n",
    "print(\"Updated model_metrics saved to 'strat_linreg_eval_metrics/model_results.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with non-zero coefficients (14 out of 362):\n",
      "  hist_roe: 0.000892\n",
      "  hist_fcf_yld: 0.000087\n",
      "  hist_pe: -0.000058\n",
      "  hist_eps_usd: 0.000013\n",
      "  hist_ebitda_ev: 0.000005\n",
      "  shares_float: 0.000000\n",
      "  shares_outstanding: -0.000000\n",
      "  hist_rd_exp_usd: -0.000000\n",
      "  net_income_usd: -0.000000\n",
      "  hist_gross_profit_usd: 0.000000\n",
      "  market_cap_usd: 0.000000\n",
      "  hist_ev_usd: -0.000000\n",
      "  hist_net_debt_usd: 0.000000\n",
      "  hist_net_chg_lt_debt_usd: -0.000000\n"
     ]
    }
   ],
   "source": [
    "# For a model stored in model_metrics\n",
    "model = model_metrics['ElasticNet_LR_Base']['model']\n",
    "non_zero_features = [(feature, coef) for feature, coef in zip(LR_Base.columns, model.coef_) if coef != 0]\n",
    "print(f\"Features with non-zero coefficients ({len(non_zero_features)} out of {len(LR_Base.columns)}):\")\n",
    "for feature, coef in sorted(non_zero_features, key=lambda x: abs(x[1]), reverse=True):\n",
    "    print(f\"  {feature}: {coef:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models in model_metrics:\n",
      "- LR_Base\n",
      "- LR_Yeo\n",
      "- LR_Base_Random\n",
      "- LR_Yeo_Random\n",
      "- Sector_Consumer Discretionary_Base\n",
      "- Sector_Consumer Discretionary_Yeo\n",
      "- Sector_Consumer Discretionary_Base_Random\n",
      "- Sector_Consumer Discretionary_Yeo_Random\n",
      "- Sector_Consumer Staples_Base\n",
      "- Sector_Consumer Staples_Yeo\n",
      "- Sector_Consumer Staples_Base_Random\n",
      "- Sector_Consumer Staples_Yeo_Random\n",
      "- Sector_Energy_Base\n",
      "- Sector_Energy_Yeo\n",
      "- Sector_Energy_Base_Random\n",
      "- Sector_Energy_Yeo_Random\n",
      "- Sector_Financials_Base\n",
      "- Sector_Financials_Yeo\n",
      "- Sector_Financials_Base_Random\n",
      "- Sector_Financials_Yeo_Random\n",
      "- Sector_Health Care_Base\n",
      "- Sector_Health Care_Yeo\n",
      "- Sector_Health Care_Base_Random\n",
      "- Sector_Health Care_Yeo_Random\n",
      "- Sector_Industrials_Base\n",
      "- Sector_Industrials_Yeo\n",
      "- Sector_Industrials_Base_Random\n",
      "- Sector_Industrials_Yeo_Random\n",
      "- Sector_Information Technology_Base\n",
      "- Sector_Information Technology_Yeo\n",
      "- Sector_Information Technology_Base_Random\n",
      "- Sector_Information Technology_Yeo_Random\n",
      "- Sector_Materials_Base\n",
      "- Sector_Materials_Yeo\n",
      "- Sector_Materials_Base_Random\n",
      "- Sector_Materials_Yeo_Random\n",
      "- Sector_Real Estate_Base\n",
      "- Sector_Real Estate_Yeo\n",
      "- Sector_Real Estate_Base_Random\n",
      "- Sector_Real Estate_Yeo_Random\n",
      "- Sector_Utilities_Base\n",
      "- Sector_Utilities_Yeo\n",
      "- Sector_Utilities_Base_Random\n",
      "- Sector_Utilities_Yeo_Random\n",
      "- ElasticNet_LR_Base\n",
      "- ElasticNet_LR_Yeo\n",
      "- ElasticNet_LR_Base_Random\n",
      "- ElasticNet_LR_Yeo_Random\n"
     ]
    }
   ],
   "source": [
    "print(\"Available models in model_metrics:\")\n",
    "for key in model_metrics.keys():\n",
    "    print(f\"- {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot outcomes function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_residual_analysis_fixed(model_metrics, model_names, output_dir=None):\n",
    "    \"\"\"\n",
    "    Perform comprehensive residual analysis on selected models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_metrics : dict\n",
    "        Dictionary containing model metrics and predictions\n",
    "    model_names : list\n",
    "        List of model names to analyze\n",
    "    output_dir : str, optional\n",
    "        Directory to save plots. If None, plots are not saved.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Summary statistics of residual analysis\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import scipy.stats as stats\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    import os\n",
    "    import pickle\n",
    "    \n",
    "    # Create output directory if specified and doesn't exist\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create summary statistics dataframe\n",
    "    residual_stats = []\n",
    "    \n",
    "    # Analysis for each model - Individual plots instead of combined\n",
    "    for model_name in model_names:\n",
    "        # Extract predictions and actual values\n",
    "        metrics = model_metrics[model_name]\n",
    "        y_test = metrics['y_test'].values.flatten()\n",
    "        y_pred = metrics['y_pred'].flatten()\n",
    "        \n",
    "        # Calculate residuals\n",
    "        residuals = y_test - y_pred\n",
    "        \n",
    "        # Basic stats\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mean_residual = np.mean(residuals)\n",
    "        std_residual = np.std(residuals)\n",
    "        \n",
    "        # Test for normality (Shapiro-Wilk)\n",
    "        if len(residuals) <= 5000:  # Shapiro-Wilk limited to 5000 samples\n",
    "            shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "        else:\n",
    "            shapiro_stat, shapiro_p = np.nan, np.nan\n",
    "            \n",
    "        # Test for heteroscedasticity (Breusch-Pagan)\n",
    "        # First, fit a model to predict squared residuals from predicted values\n",
    "        bp_model = np.polyfit(y_pred, residuals**2, 1)\n",
    "        bp_fit = np.polyval(bp_model, y_pred)\n",
    "        bp_stat, bp_p = stats.pearsonr(y_pred, residuals**2)\n",
    "        \n",
    "        # Store summary statistics\n",
    "        residual_stats.append({\n",
    "            'Model': model_name,\n",
    "            'RMSE': rmse,\n",
    "            'R²': r2,\n",
    "            'Mean Residual': mean_residual,\n",
    "            'Std Residual': std_residual,\n",
    "            'Shapiro-Wilk p': shapiro_p,\n",
    "            'BP Test p': bp_p,\n",
    "            'Residual Range': [np.min(residuals), np.max(residuals)],\n",
    "            'Residual IQR': np.subtract(*np.percentile(residuals, [75, 25]))\n",
    "        })\n",
    "        \n",
    "        # Create individual figure for each model with horizontal layout\n",
    "        if output_dir:\n",
    "            fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "            plt.subplots_adjust(wspace=0.3)\n",
    "            \n",
    "            # 1. Residuals vs Predicted plot\n",
    "            ax = axes[0]\n",
    "            ax.scatter(y_pred, residuals, alpha=0.5, s=10)\n",
    "            ax.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "            \n",
    "            # Add LOESS smoothing\n",
    "            try:\n",
    "                from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "                z = lowess(residuals, y_pred, frac=0.3)\n",
    "                ax.plot(z[:, 0], z[:, 1], 'r-', linewidth=2)\n",
    "            except:\n",
    "                # If LOWESS fails, use simple polynomial fit\n",
    "                p = np.polyfit(y_pred, residuals, 2)\n",
    "                ax.plot(np.sort(y_pred), np.polyval(p, np.sort(y_pred)), 'r-', linewidth=2)\n",
    "                \n",
    "            ax.set_xlabel('Predicted Values')\n",
    "            ax.set_ylabel('Residuals')\n",
    "            ax.set_title('Residuals vs Predicted')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add model metrics to plot\n",
    "            textstr = f'RMSE: {rmse:.4f}\\nR²: {r2:.4f}\\nBP Test p: {bp_p:.6f}'\n",
    "            props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "            ax.annotate(textstr, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                        fontsize=9, verticalalignment='top', bbox=props)\n",
    "            \n",
    "            # 2. Q-Q plot (check for normality) - FIXED VERSION\n",
    "            ax = axes[1]\n",
    "            temp_fig = plt.figure()  # Create a temporary figure\n",
    "            stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "            # Get the lines and points from the current figure\n",
    "            lines = plt.gca().get_lines()\n",
    "            ax.plot(lines[0].get_xdata(), lines[0].get_ydata(), 'o', markersize=5)\n",
    "            ax.plot(lines[1].get_xdata(), lines[1].get_ydata(), 'r-')\n",
    "            plt.close(temp_fig)  # Close the temporary figure\n",
    "            ax.set_title(f'Q-Q Plot (Shapiro-Wilk p: {shapiro_p:.6f})')\n",
    "            \n",
    "            # 3. Scale-Location Plot (sqrt(|standardized residuals|) vs predicted)\n",
    "            ax = axes[2]\n",
    "            standardized_residuals = residuals / std_residual\n",
    "            ax.scatter(y_pred, np.sqrt(np.abs(standardized_residuals)), alpha=0.5, s=10)\n",
    "            \n",
    "            # Add LOESS or polynomial smoothing\n",
    "            try:\n",
    "                z = lowess(np.sqrt(np.abs(standardized_residuals)), y_pred, frac=0.3)\n",
    "                ax.plot(z[:, 0], z[:, 1], 'r-', linewidth=2)\n",
    "            except:\n",
    "                p = np.polyfit(y_pred, np.sqrt(np.abs(standardized_residuals)), 2)\n",
    "                ax.plot(np.sort(y_pred), np.polyval(p, np.sort(y_pred)), 'r-', linewidth=2)\n",
    "                \n",
    "            ax.set_xlabel('Predicted Values')\n",
    "            ax.set_ylabel('√|Standardized Residuals|')\n",
    "            ax.set_title('Scale-Location Plot')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # 4. Residual Histogram\n",
    "            ax = axes[3]\n",
    "            ax.hist(residuals, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "            ax.set_xlabel('Residual Value')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.set_title('Residual Distribution')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add normal curve overlay\n",
    "            xmin, xmax = ax.get_xlim()\n",
    "            x = np.linspace(xmin, xmax, 100)\n",
    "            p = stats.norm.pdf(x, mean_residual, std_residual)\n",
    "            p = p * (len(residuals) * (xmax - xmin) / 30) # Scale to match histogram height\n",
    "            ax.plot(x, p, 'k', linewidth=2)\n",
    "            \n",
    "            # Add metrics\n",
    "            textstr = f'Mean: {mean_residual:.4f}\\nStd: {std_residual:.4f}'\n",
    "            ax.annotate(textstr, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                        fontsize=9, verticalalignment='top', bbox=props)\n",
    "            \n",
    "            # Add overall title\n",
    "            fig.suptitle(f'Residual Analysis: {model_name}', fontsize=16)\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "            \n",
    "            # Save figure\n",
    "            plt.savefig(f'{output_dir}/{model_name}_residual_analysis.png', dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            # Create Actual vs Predicted plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "            \n",
    "            # Add perfect prediction line\n",
    "            min_val = min(np.min(y_test), np.min(y_pred))\n",
    "            max_val = max(np.max(y_test), np.max(y_pred))\n",
    "            plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "            \n",
    "            plt.xlabel('Actual Values')\n",
    "            plt.ylabel('Predicted Values')\n",
    "            plt.title(f'{model_name} - Actual vs Predicted')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add metrics to plot\n",
    "            textstr = f'RMSE: {rmse:.4f}\\nR²: {r2:.4f}'\n",
    "            props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "            plt.annotate(textstr, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                        fontsize=12, verticalalignment='top', bbox=props)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/{model_name}_actual_vs_predicted.png', dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            # Residuals by ESG Score bins\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Create ESG score bins for analysis\n",
    "            score_bins = np.linspace(np.min(y_test), np.max(y_test), 10)\n",
    "            bin_indices = np.digitize(y_test, score_bins)\n",
    "            \n",
    "            # Calculate mean residual and std for each bin\n",
    "            bin_residuals = [residuals[bin_indices == i] for i in range(1, len(score_bins)+1)]\n",
    "            bin_means = [np.mean(res) if len(res) > 0 else np.nan for res in bin_residuals]\n",
    "            bin_stds = [np.std(res) if len(res) > 0 else np.nan for res in bin_residuals]\n",
    "            bin_centers = [(score_bins[i-1] + score_bins[i])/2 if i < len(score_bins) else score_bins[-1] \n",
    "                        for i in range(1, len(score_bins)+1)]\n",
    "            \n",
    "            # Plot\n",
    "            plt.errorbar(bin_centers, bin_means, yerr=bin_stds, fmt='o-', capsize=5)\n",
    "            plt.axhline(y=0, color='r', linestyle='--')\n",
    "            plt.xlabel('ESG Score Bin')\n",
    "            plt.ylabel('Mean Residual ± Std Dev')\n",
    "            plt.title(f'{model_name} - Residuals by ESG Score')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/{model_name}_residuals_by_score.png', dpi=300)\n",
    "            plt.close()\n",
    "    \n",
    "    # Create R-squared and RMSE comparison plot\n",
    "    if output_dir and len(model_names) > 1:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        r2_values = [model_metrics[name]['R2'] for name in model_names]\n",
    "        rmse_values = [model_metrics[name]['RMSE'] for name in model_names]\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        bars = plt.bar(model_names, r2_values)\n",
    "        plt.title('R² Comparison')\n",
    "        plt.ylabel('R²')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Add values on bars\n",
    "        for bar, val in zip(bars, r2_values):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, val + 0.01, f'{val:.4f}', \n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        bars = plt.bar(model_names, rmse_values)\n",
    "        plt.title('RMSE Comparison')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Add values on bars\n",
    "        for bar, val in zip(bars, rmse_values):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, val + 0.05, f'{val:.4f}', \n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/model_performance_comparison.png', dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # NEW CODE: Add boxplot visualization for RMSE distribution\n",
    "    if output_dir:\n",
    "        # Helper function for calculating confidence intervals\n",
    "        def mean_confidence_interval(data, confidence=0.95):\n",
    "            a = 1.0 * np.array(data)\n",
    "            n = len(a)\n",
    "            m, se = np.mean(a), stats.sem(a)\n",
    "            h = se * stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "            return m, m-h, m+h\n",
    "        \n",
    "        # Try to load elasticnet parameters to extract RMSE folds\n",
    "        try:\n",
    "            with open(f'{output_dir}/../elasticnet_stratified_params.pkl', 'rb') as f:\n",
    "                elasticnet_results = pickle.load(f)\n",
    "            \n",
    "            # Create a DataFrame for the RMSE values from cross-validation\n",
    "            rmse_data = []\n",
    "            for result in elasticnet_results:\n",
    "                if 'rmse_folds' in result and isinstance(result['rmse_folds'], list):\n",
    "                    dataset = result['dataset']\n",
    "                    for fold_idx, rmse_val in enumerate(result['rmse_folds']):\n",
    "                        rmse_data.append({\n",
    "                            'Dataset': dataset,\n",
    "                            'Fold': fold_idx + 1,\n",
    "                            'RMSE': rmse_val\n",
    "                        })\n",
    "            \n",
    "            if rmse_data:\n",
    "                rmse_df = pd.DataFrame(rmse_data)\n",
    "                \n",
    "                plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                # Boxplot for RMSE distribution\n",
    "                box = sns.boxplot(x='Dataset', y='RMSE', data=rmse_df, palette='pastel')\n",
    "                \n",
    "                # Stripplot for individual fold RMSEs\n",
    "                strip = sns.stripplot(x='Dataset', y='RMSE', data=rmse_df, color='gray', alpha=0.6, jitter=True)\n",
    "                \n",
    "                # Plot mean and 95% CI as red points with error bars\n",
    "                for i, dataset in enumerate(rmse_df['Dataset'].unique()):\n",
    "                    rmse_vals = rmse_df[rmse_df['Dataset'] == dataset]['RMSE']\n",
    "                    mean = np.mean(rmse_vals)\n",
    "                    ci_low, ci_high = mean_confidence_interval(rmse_vals)[1:]\n",
    "                    err = plt.errorbar(i, mean, yerr=[[mean - ci_low], [ci_high - mean]],\n",
    "                                    fmt='o', color='red', capsize=5, label='Mean ± 95% CI' if i == 0 else \"\")\n",
    "                \n",
    "                # Title and axes\n",
    "                plt.title('ElasticNet RMSE Distribution per Dataset')\n",
    "                plt.ylabel('RMSE (lower is better)')\n",
    "                plt.xlabel('Dataset')\n",
    "                plt.xticks(rotation=15)\n",
    "                plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "                \n",
    "                # Custom legend\n",
    "                from matplotlib.lines import Line2D\n",
    "                legend_elements = [\n",
    "                    Line2D([0], [0], marker='s', color='w', label='RMSE Distribution (Boxplot)',\n",
    "                        markerfacecolor='lightblue', markersize=15),\n",
    "                    Line2D([0], [0], marker='o', color='gray', label='Individual CV Fold RMSE',\n",
    "                        linestyle='None', markersize=8, alpha=0.6),\n",
    "                    Line2D([0], [0], marker='o', color='red', label='Mean ± 95% CI',\n",
    "                        linestyle='None', markersize=8)\n",
    "                ]\n",
    "                plt.legend(handles=legend_elements, loc='upper right')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{output_dir}/elasticnet_rmse_distribution.png', dpi=300)\n",
    "                plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not create RMSE distribution plot: {str(e)}\")\n",
    "    \n",
    "    # Create a summary DataFrame\n",
    "    summary_df = pd.DataFrame(residual_stats)\n",
    "    \n",
    "    # Save summary to CSV if output directory specified\n",
    "    if output_dir:\n",
    "        summary_df.to_csv(f'{output_dir}/residual_analysis_summary.csv', index=False)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def perform_residual_analysis_fixed(model_metrics, model_names, output_dir=None):\n",
    "#     \"\"\"\n",
    "#     Perform comprehensive residual analysis on selected models.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     model_metrics : dict\n",
    "#         Dictionary containing model metrics and predictions\n",
    "#     model_names : list\n",
    "#         List of model names to analyze\n",
    "#     output_dir : str, optional\n",
    "#         Directory to save plots. If None, plots are not saved.\n",
    "    \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     pandas.DataFrame\n",
    "#         Summary statistics of residual analysis\n",
    "#     \"\"\"\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import numpy as np\n",
    "#     import pandas as pd\n",
    "#     import scipy.stats as stats\n",
    "#     from sklearn.metrics import mean_squared_error, r2_score\n",
    "#     import os\n",
    "    \n",
    "#     # Create output directory if specified and doesn't exist\n",
    "#     if output_dir:\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "#     # Create summary statistics dataframe\n",
    "#     residual_stats = []\n",
    "    \n",
    "#     # Analysis for each model - Individual plots instead of combined\n",
    "#     for model_name in model_names:\n",
    "#         # Extract predictions and actual values\n",
    "#         metrics = model_metrics[model_name]\n",
    "#         y_test = metrics['y_test'].values.flatten()\n",
    "#         y_pred = metrics['y_pred'].flatten()\n",
    "        \n",
    "#         # Calculate residuals\n",
    "#         residuals = y_test - y_pred\n",
    "        \n",
    "#         # Basic stats\n",
    "#         rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         r2 = r2_score(y_test, y_pred)\n",
    "#         mean_residual = np.mean(residuals)\n",
    "#         std_residual = np.std(residuals)\n",
    "        \n",
    "#         # Test for normality (Shapiro-Wilk)\n",
    "#         if len(residuals) <= 5000:  # Shapiro-Wilk limited to 5000 samples\n",
    "#             shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "#         else:\n",
    "#             shapiro_stat, shapiro_p = np.nan, np.nan\n",
    "            \n",
    "#         # Test for heteroscedasticity (Breusch-Pagan)\n",
    "#         # First, fit a model to predict squared residuals from predicted values\n",
    "#         bp_model = np.polyfit(y_pred, residuals**2, 1)\n",
    "#         bp_fit = np.polyval(bp_model, y_pred)\n",
    "#         bp_stat, bp_p = stats.pearsonr(y_pred, residuals**2)\n",
    "        \n",
    "#         # Store summary statistics\n",
    "#         residual_stats.append({\n",
    "#             'Model': model_name,\n",
    "#             'RMSE': rmse,\n",
    "#             'R²': r2,\n",
    "#             'Mean Residual': mean_residual,\n",
    "#             'Std Residual': std_residual,\n",
    "#             'Shapiro-Wilk p': shapiro_p,\n",
    "#             'BP Test p': bp_p,\n",
    "#             'Residual Range': [np.min(residuals), np.max(residuals)],\n",
    "#             'Residual IQR': np.subtract(*np.percentile(residuals, [75, 25]))\n",
    "#         })\n",
    "        \n",
    "#         # Create individual figure for each model with horizontal layout\n",
    "#         if output_dir:\n",
    "#             fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "#             plt.subplots_adjust(wspace=0.3)\n",
    "            \n",
    "#             # 1. Residuals vs Predicted plot\n",
    "#             ax = axes[0]\n",
    "#             ax.scatter(y_pred, residuals, alpha=0.5, s=10)\n",
    "#             ax.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "            \n",
    "#             # Add LOESS smoothing\n",
    "#             try:\n",
    "#                 from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "#                 z = lowess(residuals, y_pred, frac=0.3)\n",
    "#                 ax.plot(z[:, 0], z[:, 1], 'r-', linewidth=2)\n",
    "#             except:\n",
    "#                 # If LOWESS fails, use simple polynomial fit\n",
    "#                 p = np.polyfit(y_pred, residuals, 2)\n",
    "#                 ax.plot(np.sort(y_pred), np.polyval(p, np.sort(y_pred)), 'r-', linewidth=2)\n",
    "                \n",
    "#             ax.set_xlabel('Predicted Values')\n",
    "#             ax.set_ylabel('Residuals')\n",
    "#             ax.set_title('Residuals vs Predicted')\n",
    "#             ax.grid(True, alpha=0.3)\n",
    "            \n",
    "#             # Add model metrics to plot\n",
    "#             textstr = f'RMSE: {rmse:.4f}\\nR²: {r2:.4f}\\nBP Test p: {bp_p:.6f}'\n",
    "#             props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "#             ax.annotate(textstr, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "#                         fontsize=9, verticalalignment='top', bbox=props)\n",
    "            \n",
    "#             # 2. Q-Q plot (check for normality) - FIXED VERSION\n",
    "#             ax = axes[1]\n",
    "#             temp_fig = plt.figure()  # Create a temporary figure\n",
    "#             stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "#             # Get the lines and points from the current figure\n",
    "#             lines = plt.gca().get_lines()\n",
    "#             ax.plot(lines[0].get_xdata(), lines[0].get_ydata(), 'o', markersize=5)\n",
    "#             ax.plot(lines[1].get_xdata(), lines[1].get_ydata(), 'r-')\n",
    "#             plt.close(temp_fig)  # Close the temporary figure\n",
    "#             ax.set_title(f'Q-Q Plot (Shapiro-Wilk p: {shapiro_p:.6f})')\n",
    "            \n",
    "#             # 3. Scale-Location Plot (sqrt(|standardized residuals|) vs predicted)\n",
    "#             ax = axes[2]\n",
    "#             standardized_residuals = residuals / std_residual\n",
    "#             ax.scatter(y_pred, np.sqrt(np.abs(standardized_residuals)), alpha=0.5, s=10)\n",
    "            \n",
    "#             # Add LOESS or polynomial smoothing\n",
    "#             try:\n",
    "#                 z = lowess(np.sqrt(np.abs(standardized_residuals)), y_pred, frac=0.3)\n",
    "#                 ax.plot(z[:, 0], z[:, 1], 'r-', linewidth=2)\n",
    "#             except:\n",
    "#                 p = np.polyfit(y_pred, np.sqrt(np.abs(standardized_residuals)), 2)\n",
    "#                 ax.plot(np.sort(y_pred), np.polyval(p, np.sort(y_pred)), 'r-', linewidth=2)\n",
    "                \n",
    "#             ax.set_xlabel('Predicted Values')\n",
    "#             ax.set_ylabel('√|Standardized Residuals|')\n",
    "#             ax.set_title('Scale-Location Plot')\n",
    "#             ax.grid(True, alpha=0.3)\n",
    "            \n",
    "#             # 4. Residual Histogram\n",
    "#             ax = axes[3]\n",
    "#             ax.hist(residuals, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "#             ax.set_xlabel('Residual Value')\n",
    "#             ax.set_ylabel('Frequency')\n",
    "#             ax.set_title('Residual Distribution')\n",
    "#             ax.grid(True, alpha=0.3)\n",
    "            \n",
    "#             # Add normal curve overlay\n",
    "#             xmin, xmax = ax.get_xlim()\n",
    "#             x = np.linspace(xmin, xmax, 100)\n",
    "#             p = stats.norm.pdf(x, mean_residual, std_residual)\n",
    "#             p = p * (len(residuals) * (xmax - xmin) / 30) # Scale to match histogram height\n",
    "#             ax.plot(x, p, 'k', linewidth=2)\n",
    "            \n",
    "#             # Add metrics\n",
    "#             textstr = f'Mean: {mean_residual:.4f}\\nStd: {std_residual:.4f}'\n",
    "#             ax.annotate(textstr, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "#                         fontsize=9, verticalalignment='top', bbox=props)\n",
    "            \n",
    "#             # Add overall title\n",
    "#             fig.suptitle(f'Residual Analysis: {model_name}', fontsize=16)\n",
    "#             plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "            \n",
    "#             # Save figure\n",
    "#             plt.savefig(f'{output_dir}/{model_name}_residual_analysis.png', dpi=300)\n",
    "#             plt.close()\n",
    "            \n",
    "#             # Create Actual vs Predicted plot\n",
    "#             plt.figure(figsize=(10, 8))\n",
    "#             plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "            \n",
    "#             # Add perfect prediction line\n",
    "#             min_val = min(np.min(y_test), np.min(y_pred))\n",
    "#             max_val = max(np.max(y_test), np.max(y_pred))\n",
    "#             plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "            \n",
    "#             plt.xlabel('Actual Values')\n",
    "#             plt.ylabel('Predicted Values')\n",
    "#             plt.title(f'{model_name} - Actual vs Predicted')\n",
    "#             plt.grid(True, alpha=0.3)\n",
    "            \n",
    "#             # Add metrics to plot\n",
    "#             textstr = f'RMSE: {rmse:.4f}\\nR²: {r2:.4f}'\n",
    "#             props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "#             plt.annotate(textstr, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "#                         fontsize=12, verticalalignment='top', bbox=props)\n",
    "            \n",
    "#             plt.tight_layout()\n",
    "#             plt.savefig(f'{output_dir}/{model_name}_actual_vs_predicted.png', dpi=300)\n",
    "#             plt.close()\n",
    "            \n",
    "#             # Residuals by ESG Score bins\n",
    "#             plt.figure(figsize=(12, 8))\n",
    "            \n",
    "#             # Create ESG score bins for analysis\n",
    "#             score_bins = np.linspace(np.min(y_test), np.max(y_test), 10)\n",
    "#             bin_indices = np.digitize(y_test, score_bins)\n",
    "            \n",
    "#             # Calculate mean residual and std for each bin\n",
    "#             bin_residuals = [residuals[bin_indices == i] for i in range(1, len(score_bins)+1)]\n",
    "#             bin_means = [np.mean(res) if len(res) > 0 else np.nan for res in bin_residuals]\n",
    "#             bin_stds = [np.std(res) if len(res) > 0 else np.nan for res in bin_residuals]\n",
    "#             bin_centers = [(score_bins[i-1] + score_bins[i])/2 if i < len(score_bins) else score_bins[-1] \n",
    "#                         for i in range(1, len(score_bins)+1)]\n",
    "            \n",
    "#             # Plot\n",
    "#             plt.errorbar(bin_centers, bin_means, yerr=bin_stds, fmt='o-', capsize=5)\n",
    "#             plt.axhline(y=0, color='r', linestyle='--')\n",
    "#             plt.xlabel('ESG Score Bin')\n",
    "#             plt.ylabel('Mean Residual ± Std Dev')\n",
    "#             plt.title(f'{model_name} - Residuals by ESG Score')\n",
    "#             plt.grid(True, alpha=0.3)\n",
    "#             plt.tight_layout()\n",
    "#             plt.savefig(f'{output_dir}/{model_name}_residuals_by_score.png', dpi=300)\n",
    "#             plt.close()\n",
    "    \n",
    "#     # Create R-squared and RMSE comparison plot\n",
    "#     if output_dir and len(model_names) > 1:\n",
    "#         plt.figure(figsize=(12, 8))\n",
    "#         r2_values = [model_metrics[name]['R2'] for name in model_names]\n",
    "#         rmse_values = [model_metrics[name]['RMSE'] for name in model_names]\n",
    "        \n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         bars = plt.bar(model_names, r2_values)\n",
    "#         plt.title('R² Comparison')\n",
    "#         plt.ylabel('R²')\n",
    "#         plt.grid(True, alpha=0.3)\n",
    "#         plt.xticks(rotation=45)\n",
    "        \n",
    "#         # Add values on bars\n",
    "#         for bar, val in zip(bars, r2_values):\n",
    "#             plt.text(bar.get_x() + bar.get_width()/2, val + 0.01, f'{val:.4f}', \n",
    "#                     ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         bars = plt.bar(model_names, rmse_values)\n",
    "#         plt.title('RMSE Comparison')\n",
    "#         plt.ylabel('RMSE')\n",
    "#         plt.grid(True, alpha=0.3)\n",
    "#         plt.xticks(rotation=45)\n",
    "        \n",
    "#         # Add values on bars\n",
    "#         for bar, val in zip(bars, rmse_values):\n",
    "#             plt.text(bar.get_x() + bar.get_width()/2, val + 0.05, f'{val:.4f}', \n",
    "#                     ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'{output_dir}/model_performance_comparison.png', dpi=300)\n",
    "#         plt.close()\n",
    "    \n",
    "#     # Create a summary DataFrame\n",
    "#     summary_df = pd.DataFrame(residual_stats)\n",
    "    \n",
    "#     # Save summary to CSV if output directory specified\n",
    "#     if output_dir:\n",
    "#         summary_df.to_csv(f'{output_dir}/residual_analysis_summary.csv', index=False)\n",
    "    \n",
    "#     return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to compare\n",
    "models_to_compare = [\n",
    "    'ElasticNet_LR_Yeo_Random',  # Best overall model\n",
    "    'ElasticNet_LR_Base_Random',                    # Best linear regression model\n",
    "    'ElasticNet_LR_Base',         # To isolate effect of ElasticNet on base features\n",
    "    'ElasticNet_LR_Yeo'                      # To see effect of Yeo transform in linear model\n",
    "]\n",
    "\n",
    "# output directory\n",
    "residual_plots_dir = 'strat_linreg_eval_metrics/residual_plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_residual_analysis_fixed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run plot function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m summary_df \u001b[38;5;241m=\u001b[39m \u001b[43mperform_residual_analysis_fixed\u001b[49m(\n\u001b[1;32m      3\u001b[0m     model_metrics\u001b[38;5;241m=\u001b[39mmodel_metrics,\n\u001b[1;32m      4\u001b[0m     model_names\u001b[38;5;241m=\u001b[39mmodels_to_compare,\n\u001b[1;32m      5\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mresidual_plots_dir,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perform_residual_analysis_fixed' is not defined"
     ]
    }
   ],
   "source": [
    "# Run plot function\n",
    "summary_df = perform_residual_analysis_fixed(\n",
    "    model_metrics=model_metrics,\n",
    "    model_names=models_to_compare,\n",
    "    output_dir=residual_plots_dir,\n",
    ")\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Implement Holm Bonferroni tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 28 pairwise tests with Holm-Bonferroni correction\n",
      "                      Model A                    Model B  t-statistic  \\\n",
      "26  ElasticNet_LR_Base_Random          ElasticNet_LR_Yeo     4.891260   \n",
      "27         ElasticNet_LR_Base          ElasticNet_LR_Yeo     4.891260   \n",
      "23   ElasticNet_LR_Yeo_Random         ElasticNet_LR_Base    -4.859602   \n",
      "22   ElasticNet_LR_Yeo_Random  ElasticNet_LR_Base_Random    -4.859602   \n",
      "18              LR_Yeo_Random   ElasticNet_LR_Yeo_Random     2.621358   \n",
      "21              LR_Yeo_Random          ElasticNet_LR_Yeo     2.618367   \n",
      "9                      LR_Yeo   ElasticNet_LR_Yeo_Random     2.618109   \n",
      "12                     LR_Yeo          ElasticNet_LR_Yeo     2.616075   \n",
      "5                     LR_Base         ElasticNet_LR_Base    -1.376145   \n",
      "4                     LR_Base  ElasticNet_LR_Base_Random    -1.376145   \n",
      "6                     LR_Base          ElasticNet_LR_Yeo     1.304125   \n",
      "3                     LR_Base   ElasticNet_LR_Yeo_Random     1.303205   \n",
      "8                      LR_Yeo              LR_Yeo_Random    -1.118952   \n",
      "17             LR_Base_Random          ElasticNet_LR_Yeo     1.091578   \n",
      "14             LR_Base_Random   ElasticNet_LR_Yeo_Random     1.091114   \n",
      "15             LR_Base_Random  ElasticNet_LR_Base_Random    -1.085890   \n",
      "16             LR_Base_Random         ElasticNet_LR_Base    -1.085890   \n",
      "2                     LR_Base              LR_Yeo_Random    -0.957240   \n",
      "0                     LR_Base                     LR_Yeo    -0.928205   \n",
      "13             LR_Base_Random              LR_Yeo_Random    -0.867514   \n",
      "7                      LR_Yeo             LR_Base_Random     0.833585   \n",
      "11                     LR_Yeo         ElasticNet_LR_Base    -0.512586   \n",
      "10                     LR_Yeo  ElasticNet_LR_Base_Random    -0.512586   \n",
      "20              LR_Yeo_Random         ElasticNet_LR_Base    -0.482296   \n",
      "19              LR_Yeo_Random  ElasticNet_LR_Base_Random    -0.482296   \n",
      "1                     LR_Base             LR_Base_Random    -0.096774   \n",
      "24   ElasticNet_LR_Yeo_Random          ElasticNet_LR_Yeo    -0.007224   \n",
      "25  ElasticNet_LR_Base_Random         ElasticNet_LR_Base          NaN   \n",
      "\n",
      "     p-value    RMSE A    RMSE B  rank  adjusted threshold  significant  \n",
      "26  0.000001  1.960951  1.778302     1            0.001786        False  \n",
      "27  0.000001  1.960951  1.778302     2            0.001852        False  \n",
      "23  0.000002  1.778292  1.960951     3            0.001923        False  \n",
      "22  0.000002  1.778292  1.960951     4            0.002000        False  \n",
      "18  0.009061  1.927862  1.778292     5            0.002083        False  \n",
      "21  0.009140  1.927862  1.778302     6            0.002174        False  \n",
      "9   0.009147  1.926096  1.778292     7            0.002273        False  \n",
      "12  0.009201  1.926096  1.778302     8            0.002381        False  \n",
      "5   0.169477  1.864484  1.960951     9            0.002500        False  \n",
      "4   0.169477  1.864484  1.960951    10            0.002632        False  \n",
      "6   0.192873  1.864484  1.778302    11            0.002778        False  \n",
      "3   0.193186  1.864484  1.778292    12            0.002941        False  \n",
      "8   0.263771  1.926096  1.927862    13            0.003125        False  \n",
      "17  0.275616  1.868181  1.778302    14            0.003333        False  \n",
      "14  0.275820  1.868181  1.778292    15            0.003571        False  \n",
      "15  0.278122  1.868181  1.960951    16            0.003846        False  \n",
      "16  0.278122  1.868181  1.960951    17            0.004167        False  \n",
      "2   0.338972  1.864484  1.927862    18            0.004545        False  \n",
      "0   0.353810  1.864484  1.926096    19            0.005000        False  \n",
      "13  0.386133  1.868181  1.927862    20            0.005556        False  \n",
      "7   0.404967  1.926096  1.868181    21            0.006250        False  \n",
      "11  0.608498  1.926096  1.960951    22            0.007143        False  \n",
      "10  0.608498  1.926096  1.960951    23            0.008333        False  \n",
      "20  0.629836  1.927862  1.960951    24            0.010000        False  \n",
      "19  0.629836  1.927862  1.960951    25            0.012500        False  \n",
      "1   0.922950  1.864484  1.868181    26            0.016667        False  \n",
      "24  0.994240  1.778292  1.778302    27            0.025000        False  \n",
      "25       NaN  1.960951  1.960951    28            0.050000        False  \n",
      "\n",
      "LaTeX Table:\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\caption{Pairwise t-tests Between Models with Holm-Bonferroni Correction}\n",
      "\\label{tab:model-significance-holm}\n",
      "\\begin{tabularx}{\\textwidth}{l l c c c c c c}\n",
      "\\toprule\n",
      "\\textbf{Model A} & \\textbf{Model B} & \\textbf{RMSE A} & \\textbf{RMSE B} & \\textbf{t-statistic} & \\textbf{p-value} & \\textbf{Adj. Threshold} & \\textbf{Sig.} \\\\\n",
      "\\midrule\n",
      "ElasticNet_LR_Base_Random & ElasticNet_LR_Yeo & 1.9610 & 1.7783 & 4.891 & 0.0000 & 0.0018 &  \\\\\n",
      "ElasticNet_LR_Base & ElasticNet_LR_Yeo & 1.9610 & 1.7783 & 4.891 & 0.0000 & 0.0019 &  \\\\\n",
      "ElasticNet_LR_Yeo_Random & ElasticNet_LR_Base & 1.7783 & 1.9610 & -4.860 & 0.0000 & 0.0019 &  \\\\\n",
      "ElasticNet_LR_Yeo_Random & ElasticNet_LR_Base_Random & 1.7783 & 1.9610 & -4.860 & 0.0000 & 0.0020 &  \\\\\n",
      "LR_Yeo_Random & ElasticNet_LR_Yeo_Random & 1.9279 & 1.7783 & 2.621 & 0.0091 & 0.0021 &  \\\\\n",
      "LR_Yeo_Random & ElasticNet_LR_Yeo & 1.9279 & 1.7783 & 2.618 & 0.0091 & 0.0022 &  \\\\\n",
      "LR_Yeo & ElasticNet_LR_Yeo_Random & 1.9261 & 1.7783 & 2.618 & 0.0091 & 0.0023 &  \\\\\n",
      "LR_Yeo & ElasticNet_LR_Yeo & 1.9261 & 1.7783 & 2.616 & 0.0092 & 0.0024 &  \\\\\n",
      "LR_Base & ElasticNet_LR_Base & 1.8645 & 1.9610 & -1.376 & 0.1695 & 0.0025 &  \\\\\n",
      "LR_Base & ElasticNet_LR_Base_Random & 1.8645 & 1.9610 & -1.376 & 0.1695 & 0.0026 &  \\\\\n",
      "LR_Base & ElasticNet_LR_Yeo & 1.8645 & 1.7783 & 1.304 & 0.1929 & 0.0028 &  \\\\\n",
      "LR_Base & ElasticNet_LR_Yeo_Random & 1.8645 & 1.7783 & 1.303 & 0.1932 & 0.0029 &  \\\\\n",
      "LR_Yeo & LR_Yeo_Random & 1.9261 & 1.9279 & -1.119 & 0.2638 & 0.0031 &  \\\\\n",
      "LR_Base_Random & ElasticNet_LR_Yeo & 1.8682 & 1.7783 & 1.092 & 0.2756 & 0.0033 &  \\\\\n",
      "LR_Base_Random & ElasticNet_LR_Yeo_Random & 1.8682 & 1.7783 & 1.091 & 0.2758 & 0.0036 &  \\\\\n",
      "LR_Base_Random & ElasticNet_LR_Base_Random & 1.8682 & 1.9610 & -1.086 & 0.2781 & 0.0038 &  \\\\\n",
      "LR_Base_Random & ElasticNet_LR_Base & 1.8682 & 1.9610 & -1.086 & 0.2781 & 0.0042 &  \\\\\n",
      "LR_Base & LR_Yeo_Random & 1.8645 & 1.9279 & -0.957 & 0.3390 & 0.0045 &  \\\\\n",
      "LR_Base & LR_Yeo & 1.8645 & 1.9261 & -0.928 & 0.3538 & 0.0050 &  \\\\\n",
      "LR_Base_Random & LR_Yeo_Random & 1.8682 & 1.9279 & -0.868 & 0.3861 & 0.0056 &  \\\\\n",
      "LR_Yeo & LR_Base_Random & 1.9261 & 1.8682 & 0.834 & 0.4050 & 0.0063 &  \\\\\n",
      "LR_Yeo & ElasticNet_LR_Base & 1.9261 & 1.9610 & -0.513 & 0.6085 & 0.0071 &  \\\\\n",
      "LR_Yeo & ElasticNet_LR_Base_Random & 1.9261 & 1.9610 & -0.513 & 0.6085 & 0.0083 &  \\\\\n",
      "LR_Yeo_Random & ElasticNet_LR_Base & 1.9279 & 1.9610 & -0.482 & 0.6298 & 0.0100 &  \\\\\n",
      "LR_Yeo_Random & ElasticNet_LR_Base_Random & 1.9279 & 1.9610 & -0.482 & 0.6298 & 0.0125 &  \\\\\n",
      "LR_Base & LR_Base_Random & 1.8645 & 1.8682 & -0.097 & 0.9229 & 0.0167 &  \\\\\n",
      "ElasticNet_LR_Yeo_Random & ElasticNet_LR_Yeo & 1.7783 & 1.7783 & -0.007 & 0.9942 & 0.0250 &  \\\\\n",
      "ElasticNet_LR_Base_Random & ElasticNet_LR_Base & 1.9610 & 1.9610 & nan & nan & 0.0500 &  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabularx}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "def perform_holm_bonferroni_tests(model_metrics, model_names, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform pairwise t-tests between models with Holm-Bonferroni correction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_metrics : dict\n",
    "        Dictionary containing model metrics, including y_pred and y_test for each model\n",
    "    model_names : list\n",
    "        List of model names to compare\n",
    "    alpha : float, default=0.05\n",
    "        Overall significance level\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Results of pairwise t-tests with Holm-Bonferroni correction\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    num_tests = len(model_names) * (len(model_names) - 1) // 2\n",
    "    \n",
    "    print(f\"Running {num_tests} pairwise tests with Holm-Bonferroni correction\")\n",
    "    \n",
    "    # Collect all test results\n",
    "    for i, model_a in enumerate(model_names):\n",
    "        for j, model_b in enumerate(model_names):\n",
    "            if j <= i:  # Skip redundant comparisons\n",
    "                continue\n",
    "            \n",
    "            # Get predictions and actual values\n",
    "            y_pred_a = model_metrics[model_a]['y_pred']\n",
    "            y_pred_b = model_metrics[model_b]['y_pred']\n",
    "            y_test = model_metrics[model_a]['y_test']  # Same for both models\n",
    "            \n",
    "            # Convert to numpy arrays if they're DataFrames or Series\n",
    "            if hasattr(y_pred_a, 'values'):\n",
    "                y_pred_a = y_pred_a.values\n",
    "            if hasattr(y_pred_b, 'values'):\n",
    "                y_pred_b = y_pred_b.values\n",
    "            if hasattr(y_test, 'values'):\n",
    "                y_test = y_test.values\n",
    "                \n",
    "            # Ensure they're all flattened 1D arrays\n",
    "            y_pred_a = y_pred_a.flatten()\n",
    "            y_pred_b = y_pred_b.flatten()\n",
    "            y_test = y_test.flatten()\n",
    "            \n",
    "            # Calculate squared errors\n",
    "            squared_errors_a = np.square(y_pred_a - y_test)\n",
    "            squared_errors_b = np.square(y_pred_b - y_test)\n",
    "            \n",
    "            # Perform paired t-test\n",
    "            t_stat, p_value = stats.ttest_rel(squared_errors_a, squared_errors_b)\n",
    "            \n",
    "            # Store result\n",
    "            results.append({\n",
    "                'Model A': model_a,\n",
    "                'Model B': model_b,\n",
    "                't-statistic': t_stat,\n",
    "                'p-value': p_value,\n",
    "                'RMSE A': np.sqrt(np.mean(squared_errors_a)),\n",
    "                'RMSE B': np.sqrt(np.mean(squared_errors_b))\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Sort by p-value (ascending)\n",
    "    results_df = results_df.sort_values('p-value')\n",
    "    \n",
    "    # Apply Holm-Bonferroni correction\n",
    "    results_df['rank'] = range(1, len(results_df) + 1)\n",
    "    results_df['adjusted threshold'] = alpha / (num_tests + 1 - results_df['rank'])\n",
    "    results_df['significant'] = results_df['p-value'] < results_df['adjusted threshold']\n",
    "    \n",
    "    # Find the first non-significant test\n",
    "    try:\n",
    "        first_nonsig_idx = results_df[~results_df['significant']].index[0]\n",
    "        # Mark all tests with higher p-values as non-significant\n",
    "        results_df.loc[results_df.index >= first_nonsig_idx, 'significant'] = False\n",
    "    except IndexError:\n",
    "        # All tests are significant\n",
    "        pass\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load model metrics from pickle file\n",
    "    with open('strat_linreg_eval_metrics/model_results.pkl', 'rb') as f:\n",
    "        model_metrics = pickle.load(f)\n",
    "    \n",
    "    # Define models to compare\n",
    "    models_to_compare = [\n",
    "        'LR_Base', \n",
    "        'LR_Yeo', \n",
    "        'LR_Base_Random', \n",
    "        'LR_Yeo_Random',\n",
    "        'ElasticNet_LR_Yeo_Random',  # Best overall model\n",
    "        'ElasticNet_LR_Base_Random', # Best linear regression model\n",
    "        'ElasticNet_LR_Base',        # To isolate effect of ElasticNet on base features\n",
    "        'ElasticNet_LR_Yeo'          # To see effect of Yeo transform in linear model\n",
    "    ]\n",
    "    \n",
    "    # Run pairwise t-tests with Holm-Bonferroni correction\n",
    "    results = perform_holm_bonferroni_tests(model_metrics, models_to_compare)\n",
    "    print(results)\n",
    "    \n",
    "    # Generate LaTeX table\n",
    "    print(\"\\nLaTeX Table:\")\n",
    "    print(\"\\\\begin{table}[H]\")\n",
    "    print(\"\\\\centering\")\n",
    "    print(\"\\\\caption{Pairwise t-tests Between Models with Holm-Bonferroni Correction}\")\n",
    "    print(\"\\\\label{tab:model-significance-holm}\")\n",
    "    print(\"\\\\begin{tabularx}{\\\\textwidth}{l l c c c c c c}\")\n",
    "    print(\"\\\\toprule\")\n",
    "    print(\"\\\\textbf{Model A} & \\\\textbf{Model B} & \\\\textbf{RMSE A} & \\\\textbf{RMSE B} & \\\\textbf{t-statistic} & \\\\textbf{p-value} & \\\\textbf{Adj. Threshold} & \\\\textbf{Sig.} \\\\\\\\\")\n",
    "    print(\"\\\\midrule\")\n",
    "    \n",
    "    for _, row in results.iterrows():\n",
    "        sig_mark = '*' if row['significant'] else ''\n",
    "        print(f\"{row['Model A']} & {row['Model B']} & {row['RMSE A']:.4f} & {row['RMSE B']:.4f} & {row['t-statistic']:.3f} & {row['p-value']:.4f} & {row['adjusted threshold']:.4f} & {sig_mark} \\\\\\\\\")\n",
    "    \n",
    "    print(\"\\\\bottomrule\")\n",
    "    print(\"\\\\end{tabularx}\")\n",
    "    print(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models in the pickle file:\n",
      "- LR_Base\n",
      "- LR_Yeo\n",
      "- LR_Base_Random\n",
      "- LR_Yeo_Random\n",
      "- Sector_Consumer Discretionary_Base\n",
      "- Sector_Consumer Discretionary_Yeo\n",
      "- Sector_Consumer Discretionary_Base_Random\n",
      "- Sector_Consumer Discretionary_Yeo_Random\n",
      "- Sector_Consumer Staples_Base\n",
      "- Sector_Consumer Staples_Yeo\n",
      "- Sector_Consumer Staples_Base_Random\n",
      "- Sector_Consumer Staples_Yeo_Random\n",
      "- Sector_Energy_Base\n",
      "- Sector_Energy_Yeo\n",
      "- Sector_Energy_Base_Random\n",
      "- Sector_Energy_Yeo_Random\n",
      "- Sector_Financials_Base\n",
      "- Sector_Financials_Yeo\n",
      "- Sector_Financials_Base_Random\n",
      "- Sector_Financials_Yeo_Random\n",
      "- Sector_Health Care_Base\n",
      "- Sector_Health Care_Yeo\n",
      "- Sector_Health Care_Base_Random\n",
      "- Sector_Health Care_Yeo_Random\n",
      "- Sector_Industrials_Base\n",
      "- Sector_Industrials_Yeo\n",
      "- Sector_Industrials_Base_Random\n",
      "- Sector_Industrials_Yeo_Random\n",
      "- Sector_Information Technology_Base\n",
      "- Sector_Information Technology_Yeo\n",
      "- Sector_Information Technology_Base_Random\n",
      "- Sector_Information Technology_Yeo_Random\n",
      "- Sector_Materials_Base\n",
      "- Sector_Materials_Yeo\n",
      "- Sector_Materials_Base_Random\n",
      "- Sector_Materials_Yeo_Random\n",
      "- Sector_Real Estate_Base\n",
      "- Sector_Real Estate_Yeo\n",
      "- Sector_Real Estate_Base_Random\n",
      "- Sector_Real Estate_Yeo_Random\n",
      "- Sector_Utilities_Base\n",
      "- Sector_Utilities_Yeo\n",
      "- Sector_Utilities_Base_Random\n",
      "- Sector_Utilities_Yeo_Random\n",
      "- ElasticNet_LR_Base\n",
      "- ElasticNet_LR_Yeo\n",
      "- ElasticNet_LR_Base_Random\n",
      "- ElasticNet_LR_Yeo_Random\n"
     ]
    }
   ],
   "source": [
    "# Load the model_results.pkl file\n",
    "with open('strat_linreg_eval_metrics/model_results.pkl', 'rb') as f:\n",
    "    loaded_model_metrics = pickle.load(f)\n",
    "\n",
    "# Print the keys to see what models are stored\n",
    "print(\"Models in the pickle file:\")\n",
    "for key in loaded_model_metrics.keys():\n",
    "    print(f\"- {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the directory containing the visualization module to the Python path\n",
    "viz_path = '/mnt/d/mas_venvs/masenv/viz_utils'\n",
    "if viz_path not in sys.path:\n",
    "    sys.path.append(viz_path)\n",
    "\n",
    "# Import the module with the new name\n",
    "from model_viz import plot_metrics_comparison, plot_residual_analysis, plot_feature_importance, plot_rmse_distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR_Base</th>\n",
       "      <td>3.476302</td>\n",
       "      <td>1.450904</td>\n",
       "      <td>0.106595</td>\n",
       "      <td>1.864484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_Yeo</th>\n",
       "      <td>3.709846</td>\n",
       "      <td>1.471139</td>\n",
       "      <td>0.046575</td>\n",
       "      <td>1.926096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet_LR_Base</th>\n",
       "      <td>3.845329</td>\n",
       "      <td>1.551427</td>\n",
       "      <td>0.011756</td>\n",
       "      <td>1.960951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet_LR_Yeo</th>\n",
       "      <td>3.162359</td>\n",
       "      <td>1.415361</td>\n",
       "      <td>0.187278</td>\n",
       "      <td>1.778302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MSE       MAE        R2      RMSE\n",
       "Model                                                     \n",
       "LR_Base             3.476302  1.450904  0.106595  1.864484\n",
       "LR_Yeo              3.709846  1.471139  0.046575  1.926096\n",
       "ElasticNet_LR_Base  3.845329  1.551427  0.011756  1.960951\n",
       "ElasticNet_LR_Yeo   3.162359  1.415361  0.187278  1.778302"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of comparing multiple models\n",
    "model_metrics = {\n",
    "    'LR_Base': model_metrics['LR_Base'],\n",
    "    'LR_Yeo': model_metrics['LR_Yeo'],\n",
    "    'ElasticNet_LR_Base': model_metrics['ElasticNet_LR_Base'],\n",
    "    'ElasticNet_LR_Yeo': model_metrics['ElasticNet_LR_Yeo']\n",
    "}\n",
    "\n",
    "# Create the comparison plot\n",
    "plot_metrics_comparison(\n",
    "    model_metrics,\n",
    "    output_dir='output/metrics',\n",
    "    metric_subset=['RMSE', 'R2', 'MAE']  # Optional: specify which metrics to plot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a specific model's residuals\n",
    "plot_residual_analysis(\n",
    "    model_metrics=model_metrics,\n",
    "    model_name='ElasticNet_LR_Yeo',  # Choose the model you want to analyze\n",
    "    output_dir='output/residuals'\n",
    ")\n",
    "\n",
    "# You can analyze multiple models by calling the function for each one\n",
    "for model_name in ['LR_Base', 'ElasticNet_LR_Base']:\n",
    "    plot_residual_analysis(\n",
    "        model_metrics=model_metrics,\n",
    "        model_name=model_name,\n",
    "        output_dir=f'output/residuals/{model_name}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'feature_importances'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example with a dictionary of feature importances\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mElasticNet_LR_Yeo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature_importances\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m plot_feature_importance(\n\u001b[1;32m      5\u001b[0m     feature_importances\u001b[38;5;241m=\u001b[39mfeature_importances,\n\u001b[1;32m      6\u001b[0m     top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,  \u001b[38;5;66;03m# Show top 15 features\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/features\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Alternative with DataFrame input\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'feature_importances'"
     ]
    }
   ],
   "source": [
    "# Example with a dictionary of feature importances\n",
    "feature_importances = model_metrics['ElasticNet_LR_Yeo']['feature_importances']\n",
    "\n",
    "plot_feature_importance(\n",
    "    feature_importances=feature_importances,\n",
    "    top_n=15,  # Show top 15 features\n",
    "    output_dir='output/features'\n",
    ")\n",
    "\n",
    "# Alternative with DataFrame input\n",
    "import pandas as pd\n",
    "feature_df = pd.DataFrame({\n",
    "    'Feature': list(feature_importances.keys()),\n",
    "    'Importance': list(feature_importances.values())\n",
    "})\n",
    "plot_feature_importance(\n",
    "    feature_importances=feature_df,\n",
    "    top_n=20,\n",
    "    output_dir='output/features'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Fold</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_Base</td>\n",
       "      <td>1</td>\n",
       "      <td>1.900175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_Base</td>\n",
       "      <td>2</td>\n",
       "      <td>1.991787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR_Base</td>\n",
       "      <td>3</td>\n",
       "      <td>1.917544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR_Base</td>\n",
       "      <td>4</td>\n",
       "      <td>1.857646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR_Base</td>\n",
       "      <td>5</td>\n",
       "      <td>1.914036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR_Yeo</td>\n",
       "      <td>1</td>\n",
       "      <td>1.726230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR_Yeo</td>\n",
       "      <td>2</td>\n",
       "      <td>1.830957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR_Yeo</td>\n",
       "      <td>3</td>\n",
       "      <td>1.759412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR_Yeo</td>\n",
       "      <td>4</td>\n",
       "      <td>1.657172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR_Yeo</td>\n",
       "      <td>5</td>\n",
       "      <td>1.586418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LR_Base_random</td>\n",
       "      <td>1</td>\n",
       "      <td>1.900175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LR_Base_random</td>\n",
       "      <td>2</td>\n",
       "      <td>1.991787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LR_Base_random</td>\n",
       "      <td>3</td>\n",
       "      <td>1.917544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LR_Base_random</td>\n",
       "      <td>4</td>\n",
       "      <td>1.857646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LR_Base_random</td>\n",
       "      <td>5</td>\n",
       "      <td>1.914036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR_Yeo_random</td>\n",
       "      <td>1</td>\n",
       "      <td>1.725928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR_Yeo_random</td>\n",
       "      <td>2</td>\n",
       "      <td>1.832478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR_Yeo_random</td>\n",
       "      <td>3</td>\n",
       "      <td>1.760375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LR_Yeo_random</td>\n",
       "      <td>4</td>\n",
       "      <td>1.659058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LR_Yeo_random</td>\n",
       "      <td>5</td>\n",
       "      <td>1.585983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dataset  Fold      RMSE\n",
       "0          LR_Base     1  1.900175\n",
       "1          LR_Base     2  1.991787\n",
       "2          LR_Base     3  1.917544\n",
       "3          LR_Base     4  1.857646\n",
       "4          LR_Base     5  1.914036\n",
       "5           LR_Yeo     1  1.726230\n",
       "6           LR_Yeo     2  1.830957\n",
       "7           LR_Yeo     3  1.759412\n",
       "8           LR_Yeo     4  1.657172\n",
       "9           LR_Yeo     5  1.586418\n",
       "10  LR_Base_random     1  1.900175\n",
       "11  LR_Base_random     2  1.991787\n",
       "12  LR_Base_random     3  1.917544\n",
       "13  LR_Base_random     4  1.857646\n",
       "14  LR_Base_random     5  1.914036\n",
       "15   LR_Yeo_random     1  1.725928\n",
       "16   LR_Yeo_random     2  1.832478\n",
       "17   LR_Yeo_random     3  1.760375\n",
       "18   LR_Yeo_random     4  1.659058\n",
       "19   LR_Yeo_random     5  1.585983"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot RMSE distribution from your CV results file\n",
    "plot_rmse_distribution(\n",
    "    results_file='strat_linreg_eval_metrics/elasticnet_stratified_params.pkl',\n",
    "    output_dir='output/cv_results'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_metrics_comparison() got an unexpected keyword argument 'dpi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This is just an example of how you could modify a function call with more parameters:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplot_metrics_comparison\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput/metrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_subset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRMSE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mR2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# Higher resolution\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Custom figure size\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Different output format\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_metrics_comparison() got an unexpected keyword argument 'dpi'"
     ]
    }
   ],
   "source": [
    "# This is just an example of how you could modify a function call with more parameters:\n",
    "plot_metrics_comparison(\n",
    "    model_metrics=model_metrics,\n",
    "    output_dir='output/metrics',\n",
    "    metric_subset=['RMSE', 'R2'],\n",
    "    dpi=600,               # Higher resolution\n",
    "    figsize=(12, 8),       # Custom figure size\n",
    "    output_format='pdf'    # Different output format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom modules\n",
    "from permutation_importance import (\n",
    "    load_data, \n",
    "    run_permutation_importance, \n",
    "    compare_feature_importances\n",
    ")\n",
    "from feature_importance_analysis import analyze_feature_importances\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define custom paths\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# Single pkl file path with all your data\n",
    "MODEL_RESULTS_PATH = os.path.join(BASE_DIR, 'strat_linreg_eval_metrics', 'model_results.pkl')\n",
    "\n",
    "# Path for data files (if needed)\n",
    "FEATURE_PATH = os.path.join(BASE_DIR, 'data', 'combined_df_for_ml_models.csv')\n",
    "SCORE_PATH = os.path.join(BASE_DIR, 'data', 'score.csv')\n",
    "\n",
    "# Define output paths\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'strat_linreg_eval_metrics')  # Custom output directory as requested\n",
    "PERMUTATION_DIR = os.path.join(OUTPUT_DIR, 'permutation_importance')\n",
    "ANALYSIS_DIR = os.path.join(PERMUTATION_DIR, 'analysis')\n",
    "COMPARISON_DIR = os.path.join(PERMUTATION_DIR, 'comparisons')\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(PERMUTATION_DIR, exist_ok=True)\n",
    "os.makedirs(ANALYSIS_DIR, exist_ok=True)\n",
    "os.makedirs(COMPARISON_DIR, exist_ok=True)\n",
    "\n",
    "# Load the single pickle file containing all data\n",
    "with open(MODEL_RESULTS_PATH, 'rb') as f:\n",
    "    results_data = pickle.load(f)\n",
    "\n",
    "# Extract the required data from your pickle file\n",
    "# This depends on how your data is structured. Here's an example:\n",
    "model_metrics = results_data['model_metrics']  # Adjust keys based on your actual structure\n",
    "data_dict = results_data['data_dict']\n",
    "base_columns = results_data['base_columns']\n",
    "yeo_columns = results_data['yeo_columns']\n",
    "\n",
    "# Define models to analyze\n",
    "models_to_analyze = [\n",
    "    'LR_Base',\n",
    "    'LR_Yeo',\n",
    "    'LR_Base_elasticnet',\n",
    "    'LR_Yeo_elasticnet'\n",
    "]\n",
    "\n",
    "# Define custom model-dataset mapping using data from your pkl\n",
    "custom_model_datasets = {\n",
    "    'LR_Base': data_dict['LR_Base'],\n",
    "    'LR_Yeo': data_dict['LR_Yeo'],\n",
    "    'LR_Base_elasticnet': data_dict['LR_Base'],\n",
    "    'LR_Yeo_elasticnet': data_dict['LR_Yeo']\n",
    "}\n",
    "\n",
    "# Run permutation importance with the data from your single pkl file\n",
    "importances = run_permutation_importance(\n",
    "    model_metrics=model_metrics,\n",
    "    models_to_analyze=models_to_analyze,\n",
    "    data_dict=data_dict,\n",
    "    model_datasets=custom_model_datasets,\n",
    "    output_dir=PERMUTATION_DIR,\n",
    "    elasticnet_params_path=None,  # Not needed if params are in your single pkl file\n",
    "    n_repeats=10,\n",
    "    max_features=20\n",
    ")\n",
    "\n",
    "# Run model comparisons\n",
    "compare_feature_importances(\n",
    "    all_importances=importances,\n",
    "    output_dir=COMPARISON_DIR\n",
    ")\n",
    "\n",
    "# Run comprehensive analysis\n",
    "importance_df = analyze_feature_importances(\n",
    "    model_metrics_path=MODEL_RESULTS_PATH,  # Your single pkl file path\n",
    "    output_dir=ANALYSIS_DIR\n",
    ")\n",
    "\n",
    "# Save the updated results back to the original path\n",
    "results_data['model_metrics'] = model_metrics  # Update the model_metrics component\n",
    "with open(MODEL_RESULTS_PATH, 'wb') as f:\n",
    "    pickle.dump(results_data, f)\n",
    "\n",
    "print(f\"Analysis complete. All results saved to {OUTPUT_DIR}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
