# Data Schema Documentation

This document defines the required structure for all data files used by the ML pipeline.

## Overview

The ML pipeline requires specific data files to be generated by the ESG-Score-EDA repository. These files must follow exact specifications for the pipeline to function correctly.

## Required Files and Schemas

### 1. Tree Models Dataset
**File**: `data/processed/tree_models_dataset.csv`

**Purpose**: Used by tree-based models (XGBoost, LightGBM, CatBoost) with native categorical support.

**Schema**:
```
Index: issuer_name (string) - Company identifier

Numerical Features (26 raw + 26 transformed = 52 total):
- Raw features:
  - market_cap_usd (float64)
  - net_income_usd (float64)
  - hist_pe (float64)
  - hist_book_px (float64)
  - hist_fcf_yld (float64)
  - hist_ebitda_ev (float64)
  - hist_roe (float64)
  - hist_roic (float64)
  - hist_roa (float64)
  - hist_gross_profit_usd (float64)
  - hist_net_chg_lt_debt_usd (float64)
  - hist_net_debt_usd (float64)
  - hist_ev_usd (float64)
  - hist_asset_turnover (float64)
  - hist_capex_sales (float64)
  - hist_capex_depr (float64)
  - hist_rd_exp_usd (float64)
  - hist_eps_usd (float64)
  - return_usd (float64)
  - vola (float64)
  - beta (float64)
  - shares_outstanding (float64)
  - shares_float (float64)
  - top_1_shareholder_percentage (float64)
  - top_2_shareholder_percentage (float64)
  - top_3_shareholder_percentage (float64)

- Yeo-Johnson transformed features (same as above with yeo_joh_ prefix):
  - yeo_joh_market_cap_usd (float64)
  - yeo_joh_net_income_usd (float64)
  - ... (all 26 features transformed)

Categorical Features (7 total) - stored as string/object type:
- gics_sector (object)
- gics_sub_ind (object)
- issuer_cntry_domicile_name (object)
- cntry_of_risk (object)
- top_1_shareholder_location (object)
- top_2_shareholder_location (object)
- top_3_shareholder_location (object)

Total columns: 60 (1 index + 52 numerical + 7 categorical)
```

### 2. Linear Models Dataset
**File**: `data/processed/linear_models_dataset.csv`

**Purpose**: Used by linear models (Linear Regression, ElasticNet) with one-hot encoded features.

**Schema**:
```
Index: issuer_name (string) - Company identifier

Features (all float64):
- All numerical features from tree models dataset (52 columns)
- One-hot encoded categorical features (~310 columns):
  - Pattern: {feature_name}_{category_value}
  - Example: gics_sector_Energy, gics_sector_Materials, etc.
  - Binary values: 0 or 1

Total columns: ~362 (varies based on unique categorical values)
```

### 3. Categorical Mappings
**File**: `data/processed/categorical_mappings.pkl`

**Purpose**: Maps categorical features to their one-hot encoded column names.

**Schema** (Python dictionary):
```python
{
    'gics_sector': [
        'gics_sector_Communication Services',
        'gics_sector_Consumer Discretionary',
        'gics_sector_Consumer Staples',
        'gics_sector_Energy',
        'gics_sector_Financials',
        'gics_sector_Health Care',
        'gics_sector_Industrials',
        'gics_sector_Information Technology',
        'gics_sector_Materials',
        'gics_sector_Real Estate',
        'gics_sector_Utilities'
    ],
    'gics_sub_ind': [...],  # List of all sub-industry one-hot columns
    'issuer_cntry_domicile_name': [...],  # List of all country one-hot columns
    'cntry_of_risk': [...],
    'top_1_shareholder_location': [...],
    'top_2_shareholder_location': [...],
    'top_3_shareholder_location': [...]
}
```

### 4. Datasets Metadata
**File**: `data/processed/datasets_metadata.json`

**Purpose**: Contains metadata about the datasets.

**Schema**:
```json
{
    "tree_models": {
        "n_samples": 2202,
        "n_features": 59,
        "categorical_features": [
            "gics_sector",
            "gics_sub_ind",
            "issuer_cntry_domicile_name",
            "cntry_of_risk",
            "top_1_shareholder_location",
            "top_2_shareholder_location",
            "top_3_shareholder_location"
        ],
        "numerical_features": [
            "market_cap_usd",
            "net_income_usd",
            "... (all numerical feature names)"
        ]
    },
    "linear_models": {
        "n_samples": 2202,
        "n_features": 362,
        "one_hot_features": [
            "gics_sector_Energy",
            "... (all one-hot encoded column names)"
        ]
    }
}
```

### 5. Target Scores
**File**: `data/raw/score.csv`

**Purpose**: ESG scores for all companies.

**Schema**:
```
Columns:
- issuer_name (string) - Must match issuer_name in feature datasets
- esg_score (float64) - Target variable

All companies in feature datasets must have corresponding scores.
```

### 6. Source Data Files
**File**: `data/raw/combined_df_for_tree_models.csv`

**Purpose**: Source file for creating tree_models_dataset.csv

**Schema**:
```
Must contain:
- issuer_name (index)
- All 26 raw numerical features
- All 26 Yeo-Johnson transformed features (yeo_joh_ prefix)
- All 7 categorical features as strings
Total: 60 columns
```

**File**: `data/raw/combined_df_for_ml_models.csv`

**Purpose**: Source file for creating linear_models_dataset.csv

**Schema**:
```
Must contain:
- issuer_name (index)
- All features with one-hot encoded categoricals
```

### 7. Feature Selection Files
**Files**: 
- `data/pkl/base_columns.pkl` - List of base feature column names
- `data/pkl/yeo_columns.pkl` - List of Yeo-transformed feature column names

**Purpose**: Define which features belong to base vs Yeo-transformed sets.

**Schema** (Python list):
```python
# base_columns.pkl
['market_cap_usd', 'net_income_usd', ...]  # 26 base feature names

# yeo_columns.pkl
['yeo_joh_market_cap_usd', 'yeo_joh_net_income_usd', ...]  # 26 Yeo feature names
```

## Data Validation Requirements

1. **Consistency Checks**:
   - All issuer_names must be unique within each dataset
   - All issuer_names in features must exist in score.csv
   - No missing values in target scores

2. **Data Type Validation**:
   - Numerical features: float64 (handle NaN appropriately)
   - Categorical features: object/string (no mixed types)
   - One-hot encoded: float64 with values 0.0 or 1.0

3. **Shape Validation**:
   - tree_models_dataset: 60 columns (excluding index)
   - linear_models_dataset: ~362 columns (varies by categorical cardinality)
   - All datasets: 2202 rows (or current sample count)

4. **Categorical Validation**:
   - Each row must have exactly one 1.0 per categorical feature group in one-hot encoding
   - Categorical values must be consistent across datasets

## Generation Pipeline

The ESG-Score-EDA repository should:

1. Generate `combined_df_for_tree_models.csv` with both raw and Yeo features
2. Generate `combined_df_for_ml_models.csv` with one-hot encoded features
3. Ensure `score.csv` contains all company ESG scores
4. Run `create_categorical_datasets.py` to generate processed files

## Version History

- 2025-06-22: Initial schema documentation created
- 2025-06-22: Updated to reflect removal of unified/ directory
- 2025-06-22: Clarified tree models file requirements (60 columns)