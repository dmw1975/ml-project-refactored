# Visualization Documentation

All visualization-related documentation

## Table of Contents

1. [Baseline Visualization Changes](#baseline-visualization-changes)
2. [Consolidated Baseline Visualization](#consolidated-baseline-visualization)
3. [Readme New Viz](#readme-new-viz)
4. [Visualization Legacy Phaseout](#visualization-legacy-phaseout)

---

## Baseline Visualization Changes

_Source: BASELINE_VISUALIZATION_CHANGES.md (root)_

# Baseline Visualization Changes

## Summary
This document describes changes made to the baseline visualization system to prevent generating individual model-specific baseline comparison plots while maintaining the summary plots that show all models together.

## Problem
The baseline visualization system was generating individual plots for each model and metric combination:
- `CatBoost_Base_basic_MAE_vs_baseline.png`
- `CatBoost_Base_basic_MSE_vs_baseline.png`
- `CatBoost_Base_basic_performance_improvement.png`
- `CatBoost_Base_basic_R2_vs_baseline.png`
- `CatBoost_Base_basic_RMSE_vs_baseline.png`

These individual plots were:
1. Cluttering the output directory
2. Redundant with the summary plots
3. Taking extra time to generate

## Changes Made

### 1. Modified `visualization_new/plots/baselines.py`
- Added a `create_individual_model_plots` parameter (default: `False`) to the `create_metric_comparison_plots` function
- Updated the `visualize_all_baseline_comparisons` function to accept and pass this parameter
- Made the individual plot generation conditional based on this parameter
- Organized the code to clearly separate summary plot generation from individual plot generation

### 2. Updated `main.py` 
- Modified the baseline visualization calls to explicitly set `create_individual_plots=False`
- Updated both the main visualization block and the additional visualizations function

### 3. Created a cleanup script
- Added `cleanup_baseline_plots.py` to move existing individual plots to a backup directory
- The script preserves summary plots while safely archiving individual plots
- Can be run manually whenever needed

## Files Affected
1. `/mnt/d/ml_project_refactored/visualization_new/plots/baselines.py`
2. `/mnt/d/ml_project_refactored/main.py`
3. `/mnt/d/ml_project_refactored/cleanup_baseline_plots.py` (new file)

## How To Use
By default, the system now only generates summary plots. If individual plots are needed for a specific case, they can be generated by:

```python
from visualization_new.plots.baselines import visualize_all_baseline_comparisons
visualize_all_baseline_comparisons(create_individual_plots=True)
```

To clean up any existing individual plots:
```
python cleanup_baseline_plots.py
```

## Summary Plots that are Still Generated
1. `model_vs_random_comparison.png` - RMSE bar chart for all models compared to random baseline
2. `baseline_improvement.png` - Percentage improvement of each model over random baseline
3. `RMSE_comparison.png` - Grouped bar chart showing RMSE for all models and baselines
4. `R2_comparison.png` - Grouped bar chart showing R² for all models and baselines
5. `MSE_comparison.png` - Grouped bar chart showing MSE for all models and baselines
6. `MAE_comparison.png` - Grouped bar chart showing MAE for all models and baselines
7. `combined_metrics_comparison.png` - Multiple panel plot showing all metrics
---

## Consolidated Baseline Visualization

_Source: CONSOLIDATED_BASELINE_VISUALIZATION.md (root)_

# Consolidated Baseline Visualization Implementation

## Overview
Implemented a new consolidated baseline comparison visualization that combines all three baseline types (mean, median, random) into a single plot per metric, reducing redundancy and improving visual comparison.

## Changes Made

### 1. New Visualization Module
Created `/visualization_new/plots/consolidated_baselines.py` with:
- `create_consolidated_baseline_comparison()` - Creates a single plot showing all baselines
- `create_consolidated_baseline_visualizations()` - Generates plots for all metrics

### 2. Key Features
- **Single plot per metric** instead of 3 separate plots (9 plots → 3 plots)
- **All baselines shown as lines** with different styles:
  - Mean baseline: Solid red line
  - Median baseline: Dashed cyan line  
  - Random baseline: Dotted gray line
- **Improvement calculated relative to best baseline** (hardest to beat)
- **Clear labeling** shows which baseline was used for improvement calculation

### 3. Visual Enhancements
- Model performance shown as horizontal bars (colored by model type)
- Baseline lines overlaid on each model's bar
- Improvement percentage shown with baseline type (e.g., "14.3% vs Mean")
- Dual legend system: one for model types, one for baseline types

### 4. Generated Files
New consolidated plots created:
- `RMSE_consolidated_baseline_comparison.png`
- `MAE_consolidated_baseline_comparison.png`
- `R²_consolidated_baseline_comparison.png`

## Benefits
1. **Reduced redundancy** - 66% fewer plots while preserving all information
2. **Better comparison** - All baselines visible simultaneously
3. **More meaningful improvements** - Calculated against the toughest baseline
4. **Space efficient** - Easier to include in reports/presentations

## Usage
```python
from visualization_new.plots.consolidated_baselines import create_consolidated_baseline_visualizations

# Create consolidated baseline visualizations
paths = create_consolidated_baseline_visualizations(
    baseline_data_path='path/to/baseline_comparison.csv',
    output_dir='path/to/output',
    metrics=['RMSE', 'MAE', 'R²']
)
```

## Results
The visualization clearly shows that:
- Mean baseline is consistently the hardest to beat across all models
- All models show significant improvement over baselines
- Tree-based models (XGBoost, LightGBM, CatBoost) perform best
- Improvements range from ~10-14% over the mean baseline for RMSE
---

## Readme New Viz

_Source: README_NEW_VIZ.md (root)_

# New Visualization Architecture

This document provides information about the new visualization architecture implemented in the `visualization_new` package.

## Overview

The new visualization architecture is designed to be model-agnostic, modular, and extensible. It provides a standardized way to create visualizations for different model types (XGBoost, LightGBM, CatBoost, ElasticNet, etc.) without duplicating code.

## Package Structure

```
visualization_new/
├── __init__.py
├── adapters/                  # Model-specific adapters
│   ├── __init__.py
│   ├── xgboost_adapter.py
│   ├── lightgbm_adapter.py
│   └── catboost_adapter.py
├── core/                      # Core components and interfaces
│   ├── __init__.py
│   ├── interfaces.py
│   ├── base.py
│   ├── registry.py
│   └── style.py
├── plots/                     # Visualization implementations
│   ├── __init__.py
│   ├── residuals.py
│   ├── features.py
│   └── metrics.py
├── components/                # Reusable visualization components
│   ├── __init__.py
│   ├── annotations.py
│   ├── layouts.py
│   └── formats.py
├── utils/                     # Utility functions
│   ├── __init__.py
│   ├── data_prep.py
│   ├── statistics.py
│   └── io.py
└── viz_factory.py             # Simplified interface for creating visualizations
```

## Output Directory Structure

The visualization package organizes outputs using a standardized directory structure. For detailed information, see [DIRECTORY_STRUCTURE.md](visualization_new/DIRECTORY_STRUCTURE.md).

```
/outputs/visualizations/
├── features/                  # Feature importance visualizations 
│   ├── catboost/              # CatBoost feature importance plots
│   ├── lightgbm/              # LightGBM feature importance plots
│   └── xgboost/               # XGBoost feature importance plots
├── residuals/                 # Residual analysis visualizations
│   ├── catboost/              # CatBoost residual plots
│   └── xgboost/               # XGBoost residual plots
└── performance/               # Performance metrics visualizations
    ├── catboost/              # CatBoost performance plots
    ├── comparison/            # Cross-model comparison plots
    └── xgboost/               # XGBoost performance plots
```

## Key Components

### Core

- **interfaces.py**: Defines the `ModelData` interface for standardized model data access and `VisualizationConfig` for configuring visualizations.
- **base.py**: Contains base classes for visualizations (`BaseViz`, `ModelViz`, `ComparativeViz`).
- **registry.py**: Provides a registry for model adapters to support dynamic adapter selection.
- **style.py**: Centralized styling utilities for consistent visualization appearance.

### Adapters

Model-specific adapters that convert model data into the standardized `ModelData` interface:

- **xgboost_adapter.py**: Adapter for XGBoost models
- **lightgbm_adapter.py**: Adapter for LightGBM models
- **catboost_adapter.py**: Adapter for CatBoost models

### Plots

Topic-based visualization modules:

- **residuals.py**: Residual analysis visualizations
- **features.py**: Feature importance visualizations
- **metrics.py**: Performance metrics visualizations

### Components

Reusable visualization components:

- **annotations.py**: Text annotations and statistical labels
- **layouts.py**: Layout utilities for creating multi-plot figures
- **formats.py**: Formatting utilities for consistent styling

### Utils

Utility functions:

- **data_prep.py**: Data preparation functions
- **statistics.py**: Statistical analysis functions
- **io.py**: Input/output utilities

### Factory

- **viz_factory.py**: Provides a simple interface for creating visualizations

## Usage

### Basic Usage

```python
import visualization_new as viz

# Create residual plot for a specific model
viz.create_residual_plot('XGB_Base_optuna')

# Create all residual plots
viz.create_all_residual_plots()

# Create feature importance plot
viz.create_feature_importance_plot('LightGBM_Base_optuna')

# Create model comparison plot
from visualization_new.utils.io import load_all_models
models = load_all_models()
viz.create_model_comparison_plot(list(models.values()))

# Create comprehensive dashboard
viz.create_comparative_dashboard()
```

### Using Command Line

```bash
# Generate visualizations using the new architecture
python main.py --visualize-new

# Run specific model training and visualization
python main.py --train-xgboost --visualize-new

# Run the test script for the new architecture
python test_new_visualization.py
```

## Extending the Architecture

### Adding a New Model Type

1. Create a new adapter in the `adapters/` directory (e.g., `new_model_adapter.py`)
2. Implement the adapter class by extending `ModelData` or implementing the required interface
3. Register the adapter in the registry module

### Adding a New Visualization Type

1. Create a new module in the `plots/` directory (e.g., `new_plot_type.py`)
2. Implement visualization classes extending `BaseViz` or other base classes
3. Add factory functions in `viz_factory.py` to expose the new visualizations

## Benefits

1. **Modularity**: Clear separation of concerns with dedicated modules
2. **Reusability**: Common components are reused across different visualizations
3. **Consistency**: Standardized interfaces and styling
4. **Extensibility**: Easy to add support for new model types or visualizations
5. **Maintainability**: Reduced code duplication and improved organization

## Comparison with Old Architecture

The old visualization architecture had several limitations:

1. **Model-specific code**: Separate modules for each model type (xgboost_plots.py, lightgbm_plots.py, etc.)
2. **Code duplication**: Similar visualization code repeated across files
3. **Inconsistent interfaces**: Different parameters and return values across functions
4. **Limited reusability**: Difficult to extend or reuse components

The new architecture addresses these issues with a modular, component-based design that separates concerns and promotes code reuse.

## Future Improvements

1. Add more adapters for different model types
2. Implement more visualization types
3. Add interactive visualizations
4. Create a dashboard interface
5. Improve documentation with examples
---

## Visualization Legacy Phaseout

_Source: VISUALIZATION_LEGACY_PHASEOUT.md (root)_

# Legacy Visualization Phase-Out Plan

This document outlines the plan for completely phasing out the legacy visualization code in favor of the new architecture.

## Timeline

| Phase | Timeframe | Actions |
| ----- | --------- | ------- |
| 1. Deprecation | Current | Mark all legacy modules as deprecated with warnings |
| 2. Redirection | Current - 1 month | Implement import redirection to new architecture |
| 3. Legacy Mode | 1-2 months | Add `--use-legacy-viz` flag option only for emergencies |
| 4. Full Removal | 3 months | Remove legacy visualization code entirely |

## Phase 1: Deprecation (Current)

**Status: Complete**

All legacy visualization modules now include deprecation warnings:

```python
import warnings

warnings.warn(
    "This module is deprecated. Please use visualization_new package instead.",
    DeprecationWarning,
    stacklevel=2
)
```

## Phase 2: Redirection (Current - 1 month)

**Status: In Progress**

1. Update `visualization/__init__.py` to redirect imports to the new architecture:
   ```python
   from visualization_new import *
   
   # Re-export with legacy names
   plot_residuals = create_residual_plot
   plot_model_comparison = create_model_comparison_plot
   plot_feature_importance_by_model = create_feature_importance_plot
   ```

2. Update all legacy visualization modules to call their equivalents in the new architecture.

3. Update `main.py` to prioritize new visualization architecture for all flags.

## Phase 3: Legacy Mode (1-2 months)

**Status: Planned**

Add a `--use-legacy-viz` flag to `main.py` that explicitly opts in to using the legacy code:

```python
parser.add_argument('--use-legacy-viz', action='store_true',
                   help='Use legacy visualization code (DEPRECATED)')

if args.use_legacy_viz:
    warnings.warn(
        "Using legacy visualization code. This option will be removed in a future update.",
        DeprecationWarning,
        stacklevel=2
    )
    # Call legacy code
else:
    # Use new architecture (default)
```

This flag should only be used for emergency compatibility cases.

## Phase 4: Full Removal (3 months)

**Status: Planned**

1. Remove the `visualization/` directory entirely
2. Remove the `--use-legacy-viz` flag option
3. Update all scripts and notebooks to use only the new architecture
4. Update documentation to remove references to legacy visualization

## Transition Guidelines for Users

### How to Migrate

1. Replace imports:
   ```python
   # Old
   from visualization.feature_plots import plot_feature_importance_by_model
   
   # New
   from visualization_new import create_feature_importance_plot
   ```

2. Update function calls:
   ```python
   # Old
   plot_feature_importance_by_model(importance_results)
   
   # New
   create_feature_importance_plot(model_data)
   ```

3. Review directory structure:
   - Be aware that visualizations are now saved in type-based directories 
   - For example, feature importance plots are in `outputs/visualizations/features/`

### Command-Line Migration

1. Replace `--visualize` with `--visualize` (both now use the new architecture)
2. Replace model-specific visualization flags (these will continue to work but now use the new architecture)

## Implementation Notes

1. All visualizations should now be created using the `visualization_new` package.
2. The `visualization/` directory is maintained only for backward compatibility.
3. New features should only be added to the `visualization_new` package.
4. Documentation should focus exclusively on the new architecture.

## Impact Assessment

For the full phase-out to be successful, we need to ensure:

1. All features in the legacy code have equivalents in the new architecture
2. All scripts and notebooks using the legacy code are updated
3. All documentation referencing the legacy code is updated
4. Users are notified of the timeline through documentation and deprecation warnings
---

